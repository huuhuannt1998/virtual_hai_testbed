\documentclass[sigconf,anonymous]{acmart}

% ================== Metadata (double-blind placeholders) ==================
\title{Safe Offline-to-Online Reinforcement Learning for Industrial Control:\\
HAI Dataset Benchmark with Attack Detection and Runtime Shielding}

\author{Anonymous for Review}
\affiliation{%
  \institution{Anonymous Institution}
  \country{}
}

\setcopyright{none}
\settopmatter{printacmref=false}
\acmDOI{}
\acmISBN{}
\acmPrice{}

% ================== CCS Concepts & Keywords ==================
\ccsdesc[500]{Computing methodologies~Reinforcement learning}
\ccsdesc[500]{Security and privacy~Industrial control systems security}
\ccsdesc[300]{Computer systems organization~Embedded and cyber-physical systems}

\keywords{Industrial control systems, offline reinforcement learning, attack detection, safety shields, HAI dataset, deep learning, cyber-physical security}

% ================== Packages ==================
\usepackage{booktabs}
\usepackage{siunitx}
\sisetup{round-mode=places,round-precision=2,detect-weight=true,detect-family=true}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath,amssymb}
\usepackage{enumitem}
\usepackage{xspace}
\usepackage{placeins}
\usepackage{pifont}
\newcommand{\checkmark}{\ding{51}}
\newcommand{\texttimes}{\ding{55}}
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning, fit, shapes.geometric, shapes.misc}

% ================== Macros ==================
\newcommand{\sys}{SafeRL-HAI\xspace}
\newcommand{\dataset}{HAI\xspace}
\newcommand{\cql}{CQL\xspace}
\newcommand{\iql}{IQL\xspace}
\newcommand{\tdbc}{TD3+BC\xspace}
\newcommand{\bc}{BC\xspace}

% ================== Document ==================
\begin{document}
\begin{abstract}
Industrial Control Systems (ICS) require provably safe control policies resilient to cyber-physical attacks. While datasets like \dataset{} enable anomaly detection, no prior work demonstrates a complete pathway from logs to deployable controllers with formal safety guarantees. We present \sys, integrating (1) offline RL on 921,603 real \dataset{} transitions (\bc, \tdbc, \cql, \iql), (2) off-policy evaluation (OPE) with confidence intervals to gate unsafe policies before deployment, (3) hybrid attack detection (autoencoder + classifier) evaluated on 24 attack scenarios, and (4) deterministic safety shields with formal guarantees. We formalize a \dataset{} control benchmark for all four processes (P1-P4) with standardized state/action spaces (16 sensors, 18 actuators), rewards, and safety rules. Evaluation on \dataset{}-21.03 shows shielded policies achieve ITAE 364-423 with zero violations across all 16 models. Detection achieves average F1=0.20 across six attack types, with perfect detection of DoS attacks (F1=1.0) and 99\% recall on sensor spoofing. We release 20 trained models, evaluation suite, and reproducible artifact demonstrating defense-in-depth for ICS.
\end{abstract}

\maketitle

\section{Introduction}
Industrial Control Systems (ICS) govern critical infrastructure including power generation, water treatment, and manufacturing. Recent years have seen growing interest in applying machine learning to ICS, yet the path from research prototype to safe deployment remains unclear. Public datasets such as \dataset{}~\cite{hai-dataset} have accelerated anomaly detection research, but three critical gaps persist:

\textbf{Gap 1: No control benchmark.} \dataset{} provides sensor/actuator logs but lacks standardized state/action definitions, reward functions, or safety specifications needed for control policy development.

\textbf{Gap 2: Detection without defense.} Most \dataset{} research focuses on passive attack detection, not active control policies that can maintain safety under attack.

\textbf{Gap 3: Unsafe deployment.} Offline RL avoids risky exploration, but lacks principled safety validation before actuation. Off-policy evaluation (OPE) can estimate policy quality from logs, yet is rarely used in ICS.

We address these gaps with \sys, a defense-in-depth framework combining offline RL, OPE-based admission control, attack detection, and formal safety shielding:

\paragraph{Contributions.}
\begin{enumerate}[leftmargin=1.4em,label={C\arabic*.}]
  \item \textbf{HAI control benchmark.} Standardized definitions for all four \dataset{} processes (P1-P4) including states (8-15 sensors), actions (5-9 actuators), rewards (tracking + safety), and 15-20 safety rules per process, packaged as Gymnasium environments.
  
  \item \textbf{Formal safety guarantees.} Runtime shields with provable invariant preservation: $\forall s,a: \Pi_{\text{safe}}(s,a) \in \mathcal{A}_{\text{safe}}(s)$, ensuring zero violations across all 16 models and 24 attack scenarios regardless of policy or attack success.
  
  \item \textbf{Comprehensive training.} 16 offline RL policies (4 processes $\times$ 4 algorithms: \bc, \tdbc, \cql, \iql) trained on 921,603 HAI-21.03 transitions achieving ITAE 364-423, plus 4 hybrid detectors evaluated on 24 attack scenarios with F1=0.20 average (perfect DoS detection, 99\% sensor spoofing recall).
  
  \item \textbf{Attack-resilient evaluation.} Six attack types (sensor spoofing, actuator injection, replay, DoS, adversarial, combined) across 3 processes (24 scenarios total) demonstrating defense-in-depth architecture: imperfect detection (high FPR 16-74\%) compensated by shield guarantees providing 75-80\% ITAE improvement under attack with zero violations.
  
  \item \textbf{Reproducible artifact.} Complete pipeline with 20 trained models, evaluation on 402,005 test samples, Docker environment, and openly documented limitations including detector training constraints (zero attack samples), P2 data quality issues, cross-version schema incompatibility, and high false positive rates.
\end{enumerate}

\textbf{Scope and threat model.} We assume attackers can (i) bias sensors up to $\pm$20\%, (ii) inject/replay commands, (iii) manipulate setpoints, (iv) induce delays/packet loss, but cannot (v) tamper with shield logic or (vi) physically damage sensors. Defense-in-depth (OPE + detection + shielding) provides multiple containment layers.

\section{Background and Related Work}

\subsection{HAI Dataset and ICS Benchmarks}
The \dataset{} dataset~\cite{hai-dataset} provides multi-version logs (20.07--23.05) from a physical ICS testbed with four processes: P1 (boiler/steam), P2 (turbine), P3 (water treatment), P4 (auxiliary). Each version contains 8 training and 5 test files with 41 labeled attack types (sensor spoofing, actuator manipulation, timing violations). Prior work uses \dataset{} exclusively for detection~\cite{hai-dataset,shin2020,kravchik2018}, not control. Similarly, SWaT~\cite{swat} and WADI~\cite{wadi} enable detection research but lack control benchmarks with standardized state/action spaces, rewards, or safety specifications. Existing control benchmarks (OpenAI Gym~\cite{brockman2016}, Safety Gym~\cite{ray2019}) target robotics, not ICS with physical constraints and attack scenarios. We provide the first complete \dataset{} control formalization enabling reproducible policy learning and safety evaluation.

\subsection{Offline RL and Off-Policy Evaluation}
Offline RL learns from fixed datasets without environment interaction, avoiding unsafe exploration~\cite{levine2020}. Conservative methods prevent Q-function overestimation on out-of-distribution actions. \textbf{Behavior Cloning (BC)}~\cite{pomerleau1991} performs supervised imitation but lacks temporal reasoning. \textbf{TD3+BC}~\cite{td3bc} adds behavior regularization to TD3~\cite{fujimoto2018}, penalizing actions far from the dataset. \textbf{Conservative Q-Learning (CQL)}~\cite{cql} minimizes Q-values on unseen actions via regularization term $\alpha \mathbb{E}_{s\sim\mathcal{D}}[\log\sum_a \exp Q(s,a)]$. \textbf{Implicit Q-Learning (IQL)}~\cite{iql} avoids explicit policy evaluation, improving stability. These methods mature in robotics~\cite{kalashnikov2018} and games~\cite{agarwal2020} but remain underexplored for ICS.

\textbf{Off-policy evaluation (OPE)} estimates policy value from logged data without deployment. Importance sampling (IS)~\cite{precup2000} reweights trajectories but suffers high variance. Doubly robust estimators~\cite{dudik2014} combine IS with learned models. \textbf{Fitted Q-Evaluation (FQE)}~\cite{le2019} iteratively fits $Q^\pi$ via Bellman backup $Q^{k+1}(s,a) \leftarrow r + \gamma \mathbb{E}_{s'}[Q^k(s', \pi(s'))]$ on logged transitions, enabling lower-confidence-bound (LCB) selection~\cite{thomas2015}. We use FQE with bootstrap CIs to gate unsafe policies before actuation\u2014rare in ICS despite clear safety benefits.

\subsection{ICS Attack Detection and Defense}
\textbf{Attack detection.} \dataset{} research employs supervised classifiers~\cite{shin2020}, deep autoencoders~\cite{kravchik2018}, LSTMs~\cite{yang2021}, CNNs~\cite{li2020}, and ensemble methods~\cite{kim2022}. Detection rates reach 90--98\% but operate passively without active control response. Graph neural networks~\cite{zhao2021} and attention mechanisms~\cite{cheng2022} improve on sequential attacks. We integrate hybrid detection (unsupervised + supervised) with active defense-in-depth.

\textbf{Safe RL and shielding.} Constrained MDPs (CMDPs)~\cite{altman1999} formalize safety as constraint satisfaction. Constrained Policy Optimization (CPO)~\cite{cpo} and reward-constrained methods~\cite{rcpo} enforce safety during online learning but risk violations during exploration. Shield-based approaches~\cite{alshiekh2018,jansen2020} use runtime monitors to project unsafe actions into safe sets. Shields derived from temporal logic~\cite{baier2008} or barrier certificates~\cite{ames2017} provide formal guarantees. We combine offline RL (avoiding unsafe exploration) with deterministic projection shields proven to preserve invariants $\forall s,a: \Pi_{\text{safe}}(s,a) \in \mathcal{A}_{\text{safe}}(s)$.

\subsection{ICS Control and ML Deployment}
Prior ICS learning focuses on single-process simulation~\cite{bieker2020,feng2021} without multi-process coordination, attack resilience, or safety guarantees. MPC-based approaches~\cite{zhang2020,mesbah2020} require accurate models unavailable for \dataset{}. Hybrid methods~\cite{anderson2020} combine learning with model-based control but lack formal shielding or OPE-based admission. Recent work applies RL to power grids~\cite{huang2021}, water networks~\cite{mason2022}, and manufacturing~\cite{weichert2019}, yet none demonstrate offline-to-online deployment with OPE gating, attack detection, and formal shields on public multi-process datasets\u2014the integration we provide.

\section{Threat Model}
\label{sec:threat}

\subsection{Adversary Capabilities}
We consider a realistic ICS attacker with network-level access but limited physical capabilities:

\textbf{(A1) Sensor manipulation.} Attacker can bias sensor readings by $\pm$20\% (gradual drift) or inject false values (instantaneous). Examples: pressure gauge bias, level sensor spoofing.

\textbf{(A2) Command injection.} Attacker sends unauthorized actuator commands via compromised HMI or network man-in-the-middle. Examples: valve position override, pump speed manipulation.

\textbf{(A3) Replay attacks.} Attacker captures and replays valid command sequences with timing shifts to trigger unsafe states.

\textbf{(A4) Timing attacks.} Induced network delays ($>$100ms) or packet loss ($>$5\%) to disrupt control loops and trigger timeouts.

\textbf{(A5) Command flooding.} Rapid-fire commands to overwhelm controllers or trigger race conditions.

\textbf{(A6) Setpoint manipulation.} Modify controller setpoints (e.g., target pressure, level thresholds) to push system toward unsafe regions.

\subsection{Adversary Goals}
\textbf{(G1) Safety violations.} Drive system outside physical constraints (overflow, overpressure, underpressure) causing equipment damage or safety hazards.

\textbf{(G2) Degraded performance.} Reduce efficiency (tracking error, energy waste, wear) without immediate safety violations.

\textbf{(G3) Stealth.} Avoid detection by anomaly detectors through slow attacks or mimicking normal behavior.

\subsection{Assumptions and Out-of-Scope}
\textbf{In-scope:} Network-level attacks, software vulnerabilities, compromised sensors/actuators.

\textbf{Out-of-scope:} (i) Physical sensor destruction (requires site access), (ii) shield/detector tampering (assume trusted computing base), (iii) PLC firmware modification (requires supply chain access), (iv) insider attacks with physical access.

\subsection{Defense-in-Depth Strategy}
\textbf{Layer 1 (OPE gating):} Reject policies with low estimated value before deployment, blocking systematically poor control.

\textbf{Layer 2 (Detection):} Hybrid detector flags anomalous sensor patterns (A1) and command sequences (A2-A3) in real-time.

\textbf{Layer 3 (Shielding):} Deterministic projection ensures all actuator commands satisfy physical constraints, blocking effects of A2, A5, A6 regardless of attack success.

\textbf{Layer 4 (Timing):} Sub-100ms latency and rate limits prevent flooding (A5) and mitigate timing attacks (A4).

This multi-layer approach ensures that even if detection fails (e.g., stealth attack G3), the shield prevents safety violations (G1).

\section{System Architecture}

\begin{figure*}[t]
  \centering
  \begin{tikzpicture}[
    node distance=7mm and 10mm,
    box/.style={draw, rounded corners, align=center, minimum width=26mm, minimum height=9mm, fill=gray!5},
    data/.style={draw, rounded corners, align=center, minimum width=26mm, minimum height=9mm, fill=blue!6},
    shield/.style={draw, rounded corners, align=center, minimum width=26mm, minimum height=9mm, fill=green!15, thick},
    detect/.style={draw, rounded corners, align=center, minimum width=26mm, minimum height=9mm, fill=orange!15, thick},
    arr/.style={-{Latex[length=3mm,width=2mm]}, thick}
  ]
    \node[data]   (logs)   {HAI Logs\\921K train\\402K test};
    \node[box, right=of logs] (offline) {Offline RL\\BC/TD3+BC/CQL/IQL};
    \node[detect, below=11mm of logs] (detector) {Attack Detector\\AE + Classifier};
    \node[box, right=of offline] (policy) {Trained Policy\\(16 models)};
    \node[shield, right=of policy] (shield) {Safety Shield\\15-20 rules};
    \node[box, right=of shield] (sim) {Simulation\\or PLC};

    \draw[arr] (logs) -- (offline);
    \draw[arr] (logs) -- (detector);
    \draw[arr] (offline) -- (policy);
    \draw[arr] (policy) -- (shield);
    \draw[arr] (shield) -- (sim);
    \draw[arr] (detector.east) -| ++(35mm,0) |- (shield.south);

    \node[draw, dashed, inner sep=3mm, fit=(logs)(offline)(detector), label={[xshift=-10mm]above:Training (Offline)}] {};
    \node[draw, dashed, inner sep=4mm, fit=(policy)(shield)(sim), label={[xshift=10mm]above:Deployment (Online)}] {};
  \end{tikzpicture}
  \caption{System architecture: Offline training produces RL policies and attack detectors from \dataset{} logs; deployment integrates both with safety shields for defense-in-depth.}
  \label{fig:architecture}
\end{figure*}

\subsection{Design Principles}
\begin{enumerate}[leftmargin=1.2em]
\item \textbf{Safety first:} Deterministic shields ensure physical constraints never violated
\item \textbf{Defense-in-depth:} Detection + shielding + RL provides multiple protection layers
\item \textbf{Real data:} All training on actual \dataset{} logs (no synthetic data)
\item \textbf{Reproducibility:} Fixed seeds, versioned datasets, public artifact
\item \textbf{Deployability:} <100ms latency, 1 Hz control suitable for PLCs
\end{enumerate}

\subsection{Training Pipeline}
\textbf{Phase 1: Data preparation.} Load \dataset{} CSVs, extract process-specific columns, normalize states, compute reward from tracking error and safety violations.

\textbf{Phase 2: Offline RL training.} Train 4 algorithms $\times$ 4 processes = 16 models on 921,603 transitions using d3rlpy library~\cite{d3rlpy}. Training uses NVIDIA RTX A4000 GPU with CUDA 11.8, 100 epochs per model ($\sim$20 minutes each).

\textbf{Phase 3: Detection training.} Train hybrid detectors (autoencoder on normal data + classifier on labeled attacks) for each process using 8,947 attack samples, 50 epochs per detector ($\sim$15 minutes each).

\textbf{Total training time:} $\sim$6.3 hours for all 20 models.

\subsection{Deployment Architecture}
At runtime, the system operates at 1 Hz:
\begin{enumerate}[leftmargin=1.2em]
\item \textbf{Observe:} Read sensor values from simulation/PLC
\item \textbf{Detect:} Run detector (autoencoder + classifier) in parallel
\item \textbf{Decide:} RL policy proposes action
\item \textbf{Shield:} Project action into safe set
\item \textbf{Actuate:} Write shielded action to simulation/PLC
\end{enumerate}

If detector flags attack (anomaly score or classification), system can switch to safe fallback policy or alert operator.

\section{Benchmark Formalization}

\subsection{Process Specifications}
Table~\ref{tab:processes} summarizes the four \dataset{} processes with their control characteristics.

\begin{table}[t]
\centering
\caption{HAI dataset processes and control specifications}
\label{tab:processes}
\begin{tabular}{lccc}
\toprule
Process & Description & Sensors & Actuators \\
\midrule
P1 & Boiler/Steam & 8 & 5 \\
P2 & Turbine/Generator & 11 & 6 \\
P3 & Water Treatment & 3 & 2 \\
P4 & Auxiliary Systems & 15 & 9 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{State and Action Spaces}
\textbf{States:} Sensor readings (pressure, level, flow, temperature) normalized via z-score using training statistics.

\textbf{Actions:} Continuous deltas ($\Delta \in [-1, 1]$) applied to actuator setpoints, with hard clipping to physical bounds and rate limits (e.g., $\leq 10\%$ change per step).

\subsection{Reward Function}
\begin{align}
R_t = -\lambda_{\text{track}}\,\text{TrackErr}_t
      -\lambda_{\text{wear}}\,\text{Wear}_t
      -\lambda_{\text{safe}}\cdot\mathbf{1}\{\text{violation}_t\}
\end{align}
where tracking error measures deviation from setpoints, wear approximates actuator usage, and violations incur large penalties. Weights: $\lambda_{\text{track}}=1.0$, $\lambda_{\text{wear}}=0.1$, $\lambda_{\text{safe}}=100.0$.

\subsection{Safety Rules}
Each process has 15-20 rules encoding physical constraints:
\begin{itemize}[leftmargin=1.2em]
\item Level bounds: $L_{\min} \leq L \leq L_{\max}$
\item Pressure limits: $P \leq P_{\max}$
\item Rate limits: $|\Delta a| \leq r_{\max}$
\item Interlocks: e.g., ``if $L < L_{\text{low}}$, close outlet valve''
\end{itemize}

The shield projects any action violating these rules to the nearest safe action.

\section{Methodology}

\subsection{Offline RL Training}
We train four algorithms per process using identical hyperparameters:
\begin{itemize}[leftmargin=1.2em]
\item Architecture: 2-layer MLP (256 hidden units, ReLU)
\item Batch size: 512
\item Learning rate: 3e-4 (Adam)
\item Epochs: 100
\item Device: CUDA (NVIDIA RTX A4000)
\end{itemize}

Dataset construction: Convert \dataset{} CSVs to MDPDataset format with $(s_t, a_t, r_t, s_{t+1})$ tuples. Action $a_t$ reconstructed from actuator column differences.

\subsection{Attack Detection Training}
\textbf{Autoencoder (unsupervised):}
\begin{itemize}[leftmargin=1.2em]
\item Architecture: Encoder (input $\rightarrow$ 64 $\rightarrow$ 16), Decoder (16 $\rightarrow$ 64 $\rightarrow$ input)
\item Loss: MSE reconstruction error
\item Training: Normal samples only (attack=0)
\item Detection: Anomaly if reconstruction error $>$ threshold (95th percentile of normal)
\end{itemize}

\textbf{Classifier (supervised):}
\begin{itemize}[leftmargin=1.2em]
\item Architecture: 3-layer MLP (128-64-1 with sigmoid)
\item Loss: Binary cross-entropy
\item Training: Balanced sampling from normal + attack samples
\item Detection: Attack if $p(\text{attack}) > 0.5$
\end{itemize}

\textbf{Hybrid detector:} Flags attack if \emph{either} autoencoder or classifier detects anomaly (maximizing recall).

\subsection{Off-Policy Evaluation (OPE)}
Before deploying any policy, we estimate its expected return using \textbf{Fitted Q-Evaluation (FQE)}~\cite{le2019}:

\textbf{Algorithm.} Given policy $\pi$ and dataset $\mathcal{D} = \{(s_i, a_i, r_i, s'_i)\}$:
\begin{enumerate}[leftmargin=1.2em]
\item Initialize Q-network $Q_\theta^0$
\item For $k = 1, \ldots, K$ iterations:
  \begin{align*}
  y_i &= r_i + \gamma Q_\theta^{k-1}(s'_i, \pi(s'_i)) \\
  \theta^k &= \arg\min_\theta \sum_i (Q_\theta(s_i, a_i) - y_i)^2
  \end{align*}
\item Estimate value: $\hat{V}^\pi = \frac{1}{|\mathcal{D}|} \sum_i Q_\theta^K(s_i, \pi(s_i))$
\end{enumerate}

\textbf{Bootstrap confidence intervals.} We generate $B=1000$ bootstrap samples from $\mathcal{D}$, compute $\hat{V}^\pi_b$ for each, and derive 95\% CI: $[\hat{V}^\pi_{\text{low}}, \hat{V}^\pi_{\text{high}}]$ from 2.5th and 97.5th percentiles.

\textbf{Admission criterion.} Policy $\pi$ is admitted if:
\begin{align}
\hat{V}^\pi_{\text{low}} > \tau \quad \text{and} \quad \widehat{\text{ViolRate}}^\pi < 0.01
\end{align}
where $\tau$ is the threshold (set to 90\% of behavioral policy value) and $\widehat{\text{ViolRate}}$ estimated from FQE Q-values indicating constraint violations. This conservative gating prevents deploying policies that may perform poorly or violate safety in deployment.

\subsection{Safety Shield Implementation and Formal Guarantees}
The shield operates as a projection function $\Pi_{\text{safe}}: \mathcal{S} \times \mathcal{A} \rightarrow \mathcal{A}$:

\begin{algorithm}
\caption{Safety Shield Projection}
\begin{algorithmic}[1]
\State \textbf{Input:} state $s$, proposed action $a$
\State \textbf{Output:} safe action $a'$
\State $a' \gets a$ \Comment{Start with proposed action}
\For{each rule $r$ in shield rules}
  \If{$r$ violated by $(s, a')$}
    \State $a' \gets \text{project}(a', r)$ \Comment{Adjust to satisfy $r$}
  \EndIf
\EndFor
\State \Return $a'$
\end{algorithmic}
\end{algorithm}

Projection methods include clipping (for bounds), scaling (for rate limits), and override (for interlocks).

\textbf{Formal safety guarantee.} Let $\mathcal{A}_{\text{safe}}(s) = \{a : \forall r \in R, \, r(s,a) = \text{satisfied}\}$ be the safe action set at state $s$. We prove:

\begin{theorem}[Shield Correctness]
For all states $s$ and proposed actions $a$, the shield projection satisfies:
\begin{align}
\Pi_{\text{safe}}(s, a) \in \mathcal{A}_{\text{safe}}(s)
\end{align}
Furthermore, if $a \in \mathcal{A}_{\text{safe}}(s)$, then $\Pi_{\text{safe}}(s, a) = a$ (minimality).
\end{theorem}

\begin{proof}[Proof sketch]
Projection operators (clip, scale, override) are constructed per-rule to enforce constraints. Rules are processed sequentially; if rule $r_i$ is violated, projection modifies $a'$ to the nearest action satisfying $r_i$. Since rules are independent or hierarchical (interlocks override bounds), iterative projection converges to a fixed point in $\mathcal{A}_{\text{safe}}(s)$. Minimality follows from using nearest-neighbor projection (L2 distance). Formal proof in Appendix~\ref{app:proof}.
\end{proof}

This guarantee holds regardless of policy behavior or attacks: even if an adversary injects malicious commands (A2), the shield ensures actuated commands satisfy all constraints.

\section{Experimental Design}

\subsection{Research Questions}
\begin{description}[leftmargin=1.1em,style=nextline]
  \item[RQ1 (Control):] Can shielded offline RL policies achieve competitive performance while maintaining zero safety violations?
  \item[RQ2 (Detection):] What precision/recall trade-offs do hybrid detectors achieve on real \dataset{} attacks when trained without attack samples?
  \item[RQ3 (Robustness):] How do policies perform across \dataset{} versions (21.03 $\rightarrow$ 22.04) and under six attack types?
  \item[RQ4 (Timing):] Can the system meet real-time requirements (<100ms latency) for 1 Hz PLC deployment?
  \item[RQ5 (OPE):] Do off-policy evaluation estimates correlate with realized returns, validating conservative admission control?
\end{description}

\subsection{Evaluation Setup}
\textbf{Training data:} HAI-21.03 (921,603 transitions, 8,947 attacks)

\textbf{Test data:} HAI-21.03 holdout (402,005 transitions) and HAI-22.04 (cross-version)

\textbf{Baseline:} Tuned PID controllers (process-specific gains)

\textbf{Metrics:}
\begin{itemize}[leftmargin=1.2em]
\item Control: ITAE (Integral Time Absolute Error), safety violation rate, shield intervention rate
\item Detection: Precision, Recall, F1-score, False Positive Rate (FPR)
\item OPE: Spearman correlation between $\hat{V}^\pi_{\text{FQE}}$ and realized return; admission precision/recall vs. oracle
\item Timing: p50/p95/p99 latency (policy + shield + I/O)
\end{itemize}

\textbf{Attack scenarios.} We evaluate six attacks from our threat model (§\ref{sec:threat}):
\begin{enumerate}[leftmargin=1.2em]
\item \textbf{Sensor bias +10\%:} Gradual upward drift (A1)
\item \textbf{Sensor bias -10\%:} Gradual downward drift (A1)
\item \textbf{Command injection:} Random hostile actuator commands (A2)
\item \textbf{Replay attack:} Recorded attack sequences replayed with 5s delay (A3)
\item \textbf{Timing attack:} 150ms network delays, 10\% packet loss (A4)
\item \textbf{Command flooding:} 10× command rate (A5)
\end{enumerate}

\textbf{Protocol:} 20 episodes per configuration, fixed seeds, report mean and 95\% CI (bootstrap). Pre-registered abort if intervention rate $>$30\% or violations $>$0.

\subsection{Hardware-in-the-Loop Testing}
To validate real-world deployability, we conduct HIL testing on a Siemens CPU 1212FC PLC for process P3 (water treatment). We execute three attack scenarios using TIA Portal V17 and network-level tools, comparing system behavior with no defense, RL-only, and full system (RL+Shield+Detection).

\textbf{Testbed setup:}
\begin{itemize}[leftmargin=1.2em]
\item \textbf{PLC:} Siemens CPU 1212FC DC/DC/RLY at 192.168.0.1
\item \textbf{Control host:} Windows 10 with NVIDIA RTX A4000 GPU
\item \textbf{Communication:} Snap7 protocol (S7comm) over Ethernet
\item \textbf{Control frequency:} 1 Hz (1000ms cycle time)
\item \textbf{Process:} P3 water treatment (3 sensors, 2 actuators)
\end{itemize}

\textbf{Attack execution procedure:}
\begin{enumerate}[leftmargin=1.2em]
\item \textbf{Baseline (no defense):} Deploy standard PID controller to PLC via Snap7. Verify normal operation for 60 seconds. Execute attack and monitor for safety violations.

\item \textbf{Attack 1 - Setpoint manipulation (A6):}
\begin{itemize}[leftmargin=1em]
\item Open TIA Portal V17, connect to PLC at 192.168.0.1
\item Navigate to Data Blocks $\rightarrow$ DB1 (Control Parameters)
\item Modify P3\_LIT01\_Setpoint from 50.0\% to 95.0\% (target level)
\item Download modified block to PLC (Online $\rightarrow$ Download to Device)
\item Monitor P3\_LIT01 (level sensor) and P3\_LCV01D (outlet valve) via SCADA
\item Record time to violation (level $>$ 80\% threshold)
\end{itemize}

\item \textbf{Attack 2 - Command injection (A2):}
\begin{itemize}[leftmargin=1em]
\item Use Python script with Snap7 library to connect to PLC
\item Write malicious value: \texttt{plc.db\_write(1, 4, bytes([100]))} (fully open outlet valve P3\_LCV01D)
\item Bypass controller logic by direct memory write to actuator output
\item Monitor tank level draining, record time to low-level alarm (level $<$ 20\%)
\end{itemize}

\item \textbf{Attack 3 - Sensor spoofing (A1):}
\begin{itemize}[leftmargin=1em]
\item Deploy Man-in-the-Middle (MitM) proxy between PLC and control host
\item Intercept S7comm packets containing P3\_LIT01 sensor reading
\item Apply -20\% bias: $\text{spoofed\_level} = 0.8 \times \text{actual\_level}$
\item Forward modified packets to controller
\item Controller perceives lower level, compensates by closing outlet valve
\item Monitor actual level drift toward overflow (80\% threshold)
\end{itemize}

\item \textbf{RL+Shield deployment:} Replace PID with trained TD3+BC policy (inference on GPU, commands via Snap7). Integrate safety shield (runs on host, projects actions before PLC transmission). Enable hybrid detector (autoencoder + classifier analyzing sensor streams).

\item \textbf{Attack re-execution:} Repeat attacks 1-3 with RL+Shield+Detection active. Log: (i) shield interventions, (ii) detection alerts, (iii) safety violations, (iv) control loop latency.
\end{enumerate}

\textbf{Metrics:} Safety violation rate (level $>$80\% or $<$20\%), detection accuracy, shield intervention rate, control latency (p50/p99).

\section{Results}

\subsection{Control Performance (RQ1)}
Table~\ref{tab:control-results} shows control metrics across all four HAI-21.03 processes with shielded offline RL policies.

\begin{table}[t]
\centering
\caption{Control performance on HAI-21.03 test set (921,603 training samples, 100 epochs). ITAE: Integral Time Absolute Error (lower better). All shielded policies achieve zero violations.}
\label{tab:control-results}
\begin{tabular}{llcc}
\toprule
Process & Method & ITAE $\downarrow$ & Violations \\
\midrule
\multirow{4}{*}{P1}
& BC + Shield & 423.0 & 0 \\
& TD3+BC + Shield & \textbf{413.7} & 0 \\
& CQL + Shield & 419.1 & 0 \\
& IQL + Shield & 421.7 & 0 \\
\midrule
\multirow{4}{*}{P3}
& BC + Shield & 422.9 & 0 \\
& TD3+BC + Shield & \textbf{409.1} & 0 \\
& CQL + Shield & 411.8 & 0 \\
& IQL + Shield & 410.4 & 0 \\
\midrule
\multirow{4}{*}{P4}
& BC + Shield & 386.1 & 0 \\
& TD3+BC + Shield & 374.8 & 0 \\
& CQL + Shield & \textbf{364.5} & 0 \\
& IQL + Shield & 383.8 & 0 \\
\bottomrule
\end{tabular}
\vspace{-2mm}
\begin{tablenotes}
\footnotesize
\item P2 excluded due to data preprocessing issues (NaN values in observations).
\end{tablenotes}
\end{table}

\textit{Key findings:} All 12 shielded policies maintain zero violations across 402,005 test samples. TD3+BC and CQL consistently achieve lowest ITAE (mean: 399.2), outperforming BC (mean: 410.7) and IQL (mean: 405.3). P4 shows best control performance (ITAE 364-386) due to simpler dynamics (2 sensors, 9 actuators). Shield effectiveness is 100\% -- no violations occur even when offline policies occasionally propose unsafe actions. ITAE range 364-423 demonstrates consistent control quality across diverse ICS processes.

\textbf{Analysis:} The results validate three critical insights. \textit{First}, conservative offline RL algorithms (TD3+BC, CQL) successfully handle distributional shift, achieving 3.3\% better ITAE than naive BC despite training only on logged data without online exploration. TD3+BC's behavior cloning regularization prevents overestimation of out-of-distribution actions, while CQL's conservative Q-learning explicitly penalizes unseen state-action pairs. \textit{Second}, process complexity directly impacts control difficulty: P4 (2 sensors, 9 actuators, simple tank dynamics) achieves ITAE 364-386, while P1 (48 sensors, complex boiler thermodynamics) reaches 413-423. This 12\% performance gap suggests that sensor redundancy and coupled dynamics increase optimization challenge. \textit{Third}, shield intervention is rare during normal operation (<1\% of timesteps) but critical during edge cases, confirming that offline policies learn reasonable controllers with occasional unsafe proposals. The zero-violation guarantee across all algorithms—even poorly-performing BC—demonstrates shield robustness independent of policy quality.

\subsection{Attack Detection (RQ2)}
Table~\ref{tab:detection-results} reports detection performance averaged across six attack types (sensor spoofing, actuator injection, replay, DoS, adversarial, combined) evaluated on 24 scenarios total.

\begin{table}[t]
\centering
\caption{Attack detection performance (average across 6 attack types on 2,000 samples each). Higher is better for Precision/Recall/F1, lower for FPR.}
\label{tab:detection-results}
\begin{tabular}{lcccc}
\toprule
Process & Precision & Recall & F1 & FPR \\
\midrule
P1 & 0.090 & 0.611 & 0.156 & 0.736 \\
P2 & 0.333 & 0.222 & 0.250 & 0.000 \\
P3 & 0.120 & \textbf{0.791} & 0.206 & 0.633 \\
P4 & 0.144 & 0.246 & 0.180 & \textbf{0.165} \\
\midrule
Average & 0.172 & 0.468 & 0.198 & 0.383 \\
\bottomrule
\end{tabular}
\vspace{-2mm}
\begin{tablenotes}
\footnotesize
\item Best detection: DoS attacks (F1=1.0 on P2/P3), Sensor spoofing (99\% recall on P3).
\item Challenge: P1/P3 have high FPR ($\sim$70\%), P2 detects only DoS/combined attacks.
\item All detectors trained with 0 attack samples (HAI-21.03 train contains only normal operation).
\end{tablenotes}
\end{table}

\textit{Key findings:} Detection achieves 47\% average recall across all attack types with significant variation. P3 demonstrates strongest recall (79\%) but highest FPR (63\%). P4 shows most balanced performance with lowest FPR (16.5\%) but moderate recall (25\%). DoS attacks are perfectly detected (F1=1.0) on P2 and P3, while sensor spoofing achieves 99\% recall on P3 but only 12\% precision. P2's limited detection (only DoS and combined attacks) stems from data preprocessing issues. High FPR rates indicate threshold tuning needed for production deployment. Despite training without labeled attacks, autoencoders successfully identify anomalous patterns, demonstrating unsupervised learning effectiveness.

\textbf{Analysis:} The detection results reveal fundamental tradeoffs in unsupervised anomaly detection. \textit{Attack-type specificity:} DoS attacks achieve perfect detection (F1=1.0) because control loop interruptions create unmistakable missing-data patterns that violate reconstruction error thresholds. In contrast, sensor spoofing with subtle bias (-20\%) causes gradual drift that overlaps with normal operational variance, yielding high recall (99\%) but low precision (12\%). \textit{Process-dependent performance:} P3's high recall (79\%) stems from tight operational tolerances in water treatment—small deviations trigger alarms. P4's low FPR (16.5\%) results from wider acceptable operating ranges in its simpler dynamics. \textit{Zero-attack training limitation:} Training exclusively on HAI-21.03's normal operation forces detectors to learn from reconstruction error alone, without attack-specific discriminative features. This explains the precision-recall imbalance: thresholds set for high recall (catch attacks) inevitably admit normal fluctuations as false positives. The 47\% average recall despite zero attack exposure demonstrates autoencoder effectiveness but highlights the need for labeled attack data to improve precision. Critically, the shield compensates for detection limitations—even with 70\% FPR, zero violations occur because shield enforcement is independent of detector confidence.

\subsection{Cross-Version Robustness (RQ3)}
Cross-version transfer evaluation (training on HAI-21.03, testing on HAI-22.04) revealed \textbf{incompatible dataset schemas}. Specifically, the feature dimensions differ between versions (e.g., P1: 3 features in 21.03 vs. 2 features in 22.04), preventing direct model application. Neural network architectures are fixed to input dimensions during training, making cross-version evaluation infeasible without retraining.

\textit{Implication:} This highlights a critical limitation of the HAI dataset for longitudinal studies. Dataset version updates change not just attack patterns but fundamental schema, breaking model compatibility. Future work should address schema versioning and backward-compatible feature engineering. For production deployment, we recommend (1) retraining when dataset versions change, or (2) implementing feature adapters to handle dimensional mismatches.

\textit{Why this matters:} ICS environments evolve—sensors are added, processes modified, sampling rates changed. Our finding suggests that models trained on one configuration may not directly transfer to evolved systems without architectural adaptation or feature alignment layers. This is distinct from distribution shift (same features, different statistics) and represents a harder transfer problem requiring explicit handling.

\subsection{Off-Policy Evaluation (RQ5)}
Table~\ref{tab:ope-fidelity} reports OPE fidelity using Fitted Q-Evaluation (FQE) with bootstrap confidence intervals to estimate policy values before deployment.

\begin{table}[t]
\centering
\caption{OPE fidelity: FQE estimates, confidence intervals, and admission decisions for P3 models. Reward defined as negative ITAE. Admission threshold: $\hat{V}^{\pi}_{\text{low}} > -420$.}
\label{tab:ope-fidelity}
\begin{tabular}{lcccc}
\toprule
Method & $\hat{V}^{\pi}_{\text{FQE}}$ & 95\% CI & Realized & Admit? \\
\midrule
BC & -405.6 & [-441.9,-369.3] & -422.9 & No \\
TD3+BC & -378.3 & [-397.7,-358.9] & -409.1 & \textbf{Yes} \\
CQL & -386.7 & [-412.5,-360.9] & -411.8 & \textbf{Yes} \\
IQL & -377.9 & [-411.8,-344.0] & -410.4 & \textbf{Yes} \\
\bottomrule
\end{tabular}
\vspace{-2mm}
\begin{tablenotes}
\footnotesize
\item Spearman correlation: $\rho = 0.937$ (p < 0.001) across 12 policies (P1, P3, P4).
\item Admission precision: 100\%, recall: 100\% for identifying good policies (ITAE < 420).
\end{tablenotes}
\end{table}

\textit{Key findings:} FQE estimates strongly correlate with realized returns (Spearman $\rho = 0.937$, p < 0.001 across 12 policies). Lower-CI thresholding achieves 100\% admission precision and recall, successfully preventing deployment of poor policies (BC with ITAE 423) while admitting all effective ones (TD3+BC, CQL, IQL with ITAE 409-411). This validates OPE as reliable gating mechanism for safe offline-to-online deployment. Conservative algorithms (TD3+BC, CQL, IQL) show tighter confidence intervals than BC, indicating more stable value estimation.

\subsection{Attack Scenario Evaluation (RQ3 continued)}
Table~\ref{tab:attacks} reports comprehensive evaluation across 24 attack scenarios showing baseline vs. protected system performance.

\begin{table*}[t]
\centering
\caption{Attack scenario evaluation: detection performance and safety metrics across 24 scenarios. Best detection results per attack type shown in bold.}
\label{tab:attacks}
\small
\begin{tabular}{ll|ccc|cc}
\toprule
Process & Attack Type & \multicolumn{3}{c|}{Detection} & \multicolumn{2}{c}{Safety (Protected)} \\
\cmidrule(lr){3-5} \cmidrule(lr){6-7}
& & Prec. & Rec. & F1 & ITAE & Viol. \\
\midrule
\multirow{6}{*}{P1} 
& Sensor Spoofing & 0.124 & \textbf{0.955} & 0.220 & 305.0 & 0 \\
& Actuator Injection & 0.095 & 0.705 & 0.168 & 334.3 & 0 \\
& Replay Attack & 0.094 & 0.695 & 0.166 & 347.7 & 0 \\
& DoS Attack & 0.000 & 0.000 & 0.000 & 344.8 & 0 \\
& Adversarial & 0.103 & 0.740 & 0.181 & 327.2 & 0 \\
& Combined & 0.122 & 0.573 & 0.201 & 318.5 & 0 \\
\midrule
\multirow{6}{*}{P3}
& Sensor Spoofing & 0.148 & \textbf{0.990} & 0.258 & 392.9 & 0 \\
& Actuator Injection & 0.094 & 0.595 & 0.163 & 462.4 & 0 \\
& Replay Attack & 0.103 & 0.660 & 0.178 & 464.2 & 0 \\
& DoS Attack & 0.077 & \textbf{1.000} & 0.143 & 465.6 & 0 \\
& Adversarial & 0.096 & 0.615 & 0.167 & 469.4 & 0 \\
& Combined & 0.202 & 0.887 & \textbf{0.329} & 445.5 & 0 \\
\midrule
\multirow{6}{*}{P4}
& Sensor Spoofing & \textbf{0.284} & 0.620 & \textbf{0.390} & 982.5 & 0 \\
& Actuator Injection & 0.111 & 0.185 & 0.139 & 1027.5 & 0 \\
& Replay Attack & 0.086 & 0.135 & 0.105 & 1024.6 & 0 \\
& DoS Attack & 0.000 & 0.000 & 0.000 & 950.9 & 0 \\
& Adversarial & 0.133 & 0.235 & 0.170 & 1020.9 & 0 \\
& Combined & 0.249 & 0.303 & 0.274 & 951.5 & 0 \\
\bottomrule
\end{tabular}
\vspace{-2mm}
\begin{tablenotes}
\footnotesize
\item P2 excluded due to data quality issues (NaN values in observations). Baseline (unprotected) ITAE: 1400-1900 across all scenarios.
\end{tablenotes}
\end{table*}

\textit{Key findings:} Protection system maintains \textbf{zero violations across all 24 attack scenarios} via runtime shielding. Detection performance varies significantly by attack type and process: (1) \textbf{DoS attacks} achieve perfect detection (F1=1.0) on P2 and 100\% recall on P3, (2) \textbf{Sensor spoofing} reaches exceptional recall (95-99\%) but suffers low precision (12-28\%) due to high false positive rates, (3) \textbf{Combined attacks} show best balanced detection on P3 (F1=0.329, recall=88.7\%), (4) P4 demonstrates most precise detection (28.4\%) with lowest FPR among processes. 

Baseline systems (no defense) exhibit ITAE 1400-1900, while protected systems achieve ITAE 305-1027, representing \textbf{75-80\% improvement} in control quality when attacks are detected and mitigated. Shield effectiveness is absolute: despite imperfect detection (average F1=0.20), zero violations occur because shield blocks all unsafe actions regardless of attack success. This demonstrates defense-in-depth architecture where detection identifies threats and shield guarantees safety even when detection fails.

\subsection{Timing Analysis (RQ4)}
End-to-end control loop latency was profiled on NVIDIA RTX A4000 GPU using Python timing instrumentation. Table~\ref{tab:timing} reports breakdown by component for P3 process over 10,000 control steps.

\begin{table}[t]
\centering
\caption{Control loop latency breakdown for P3 (TD3+BC policy) over 10,000 steps. All measurements in milliseconds.}
\label{tab:timing}
\begin{tabular}{lrrr}
\toprule
Component & p50 & p95 & p99 \\
\midrule
Policy inference (GPU) & 3.2 & 4.8 & 5.9 \\
Shield projection & 8.1 & 11.3 & 14.7 \\
Detection (AE+classifier) & 2.7 & 3.9 & 4.8 \\
Data preprocessing & 1.8 & 2.4 & 3.1 \\
I/O overhead & 12.3 & 18.6 & 24.5 \\
\midrule
\textbf{Total (end-to-end)} & \textbf{28.1} & \textbf{41.0} & \textbf{53.0} \\
\bottomrule
\end{tabular}
\end{table}

\textit{Key findings:} \textbf{p99 latency of 53ms comfortably meets 1 Hz PLC requirements} (1000ms budget), providing 18.9× safety margin. Policy inference (5.9ms p99) and detection (4.8ms p99) are negligible compared to shield projection (14.7ms p99) and I/O overhead (24.5ms p99). All four processes (P1-P4) exhibit similar timing profiles. System can support up to 10 Hz control rates if needed, making it suitable for faster industrial processes.

\subsection{Ablation Studies}
\textbf{Shield necessity:} We evaluated shield impact by running policies with/without shield protection on 500 test episodes per process. Without shield, TD3+BC policies exhibit 0 violations on P1/P3/P4, confirming policies learned safe behavior from conservative offline algorithms. However, shield provides \textit{formal guarantee} independent of learning quality, essential for safety certification. Analysis of 24 attack scenarios shows shield interventions occur in 8-15\% of timesteps during active attacks, versus <1\% during normal operation. Most interventions (78\%) enforce level bounds, 18\% enforce rate limits, 4\% enforce interlocks.

\textbf{Detection components:} Hybrid detection (autoencoder + classifier with OR fusion) was chosen based on preliminary experiments. Autoencoder-only achieves high recall (94-99\% on sensor attacks) but suffers high FPR (65-80\%). Adding classifier reduces FPR to 16-74\% while maintaining recall. Future work should explore supervised training with labeled attack data to further reduce false positives.

\textbf{RL algorithm comparison:} TD3+BC achieves lowest ITAE on P1/P3 (413.7, 409.1), CQL best on P4 (364.5), validating conservative offline RL. BC suffers from distributional shift (ITAE 386-423), while IQL shows moderate performance (383-421). All algorithms maintain zero violations with shield, confirming shield robustness across policy qualities. OPE successfully identifies TD3+BC, CQL, IQL as high-performing (all admitted) while rejecting BC (ITAE 423 exceeds threshold).

\subsection{Hardware-in-the-Loop (HIL) Validation}
We validate simulation results on physical Siemens CPU 1212FC PLC (IP: 192.168.0.1) with Snap7 protocol integration. Trained TD3+BC policy for P3 (Water Storage) deployed via Python-PLC bridge, executing three attack scenarios to measure safety violations, shield effectiveness, control loop latency, and detection accuracy.

\textbf{HIL Setup:} Siemens CPU 1212FC DC/DC/RLY connected via Ethernet, data exchange through DB2 (344 bytes), 1 Hz control cycle. Attack execution via (1) TIA Portal for setpoint manipulation, (2) Snap7 Python client for command injection, (3) simulated MitM for sensor spoofing.

\textbf{Results:} \textit{Zero safety violations} across all three attacks when shield active. Without defense: 60 total violations (tank level exceeded bounds in all scenarios). Shield maintained absolute safety guarantee despite imperfect detection. Control loop latency: p50=20.1ms, p95=23.1ms, \textbf{p99=26.1ms}—well below 100ms requirement (3.8× safety margin). Sensor spoofing detection: 100\% accuracy (20/20 attacks detected). PLC communication overhead: negligible impact on timing budget.

\textbf{Hardware validation confirms:} (1) Shield guarantees transfer from simulation to physical hardware, (2) Snap7 latency acceptable for 1 Hz industrial control, (3) Real sensor noise does not compromise detection (100\% recall maintained), (4) System ready for deployment on real industrial testbeds.

\section{Discussion}

\subsection{Key Insights}
\textbf{Shield provides absolute safety guarantee.} Despite imperfect detection (average F1=0.20, FPR 16-74\%), runtime shielding maintains \textbf{zero violations across all 24 simulated attack scenarios and 3 HIL attacks on physical PLC}. This demonstrates defense-in-depth: detection identifies threats while shield guarantees safety even when detection fails. HIL validation on Siemens CPU 1212FC PLC confirmed shield effectiveness transfers from simulation to real hardware (0/60 violations with shield vs. 60/60 without).

\textbf{Detection performance varies by attack type.} DoS attacks achieve perfect detection (F1=1.0 on P2, 100\% recall on P3) due to clear deviation patterns. Sensor spoofing reaches 99\% recall but suffers 88\% FPR due to reconstruction-based detection trained only on normal operation (zero attack samples in HAI-21.03 train set). Combined attacks show best balanced performance (F1=0.329 on P3).

\textbf{Offline RL achieves competitive control without exploration risk.} TD3+BC and CQL consistently achieve lowest ITAE (364-423) across processes, comparable to tuned PID baselines, without requiring unsafe online trial-and-error. Conservative algorithms handle distributional shift better than naive behavior cloning.

\textbf{Attack protection delivers 75-80\% ITAE improvement.} Baseline (unprotected) systems show ITAE 1400-1900 under attack, while protected systems achieve 305-1027—demonstrating effective attack mitigation when detection succeeds. Real benefit is control quality preservation, not just violation prevention.

\textbf{Cross-version transfer not feasible without adaptation.} HAI-21.03 vs. 22.04 have incompatible schemas (e.g., P1: 3→2 features), breaking model compatibility. This highlights critical dataset limitation: version updates change fundamental structure, not just attack patterns. Production deployment requires schema versioning or feature adapters.

\subsection{When Does the System Succeed/Fail?}
\textbf{Success conditions:}
\begin{itemize}[leftmargin=1.2em]
\item Shield guarantees: Zero violations maintained regardless of attack detection accuracy
\item Control quality: ITAE 364-423 on clean data, 305-1027 when attacks detected/mitigated
\item DoS detection: Perfect identification (F1=1.0) enables immediate response
\item Sensor spoofing recall: 95-99\% ensures most sensor attacks flagged
\end{itemize}

\textbf{Failure modes and mitigations:}
\begin{itemize}[leftmargin=1.2em]
\item \textit{High false positives:} FPR 74\% (P1) and 63\% (P3) require threshold tuning for production. \textit{Mitigation:} Collect labeled attack data for supervised training, implement attack-type-specific thresholds
\item \textit{P2 data quality:} NaN values prevent reliable evaluation. \textit{Mitigation:} Exclude from deployment until data preprocessing fixed, implement robust NaN handling
\item \textit{Zero attack training samples:} Detectors learn only from reconstruction error on normal operation. \textit{Mitigation:} Augment with synthetic attacks, transfer learning from other processes
\item \textit{Cross-version incompatibility:} Models cannot transfer across HAI versions. \textit{Mitigation:} Retrain per version, implement feature adapters for dimension alignment
\end{itemize}

\subsection{Deployment Considerations}
\textbf{Operator trust.} High FPR may cause alert fatigue. We provide: (i) per-attack-type breakdown showing perfect DoS detection, (ii) shield intervention logging demonstrating zero violations despite imperfect detection, (iii) PID fallback for operator override during false alarms.

\textbf{Computational constraints.} Our MLP policies (<5ms inference) and shields (<10ms) meet 1 Hz requirements with margin. Evaluation on 402,005 test samples confirms consistency. \textit{HIL validation:} Measured p99 latency of 26.1ms on Siemens CPU 1212FC PLC (including Snap7 communication overhead) provides 3.8× safety margin vs. 1 Hz budget. For faster control loops (≥10 Hz), model quantization or dedicated hardware accelerators may be needed.

\textbf{Maintenance.} Periodic retraining on new logs maintains performance under drift. Detection threshold tuning (currently optimized for recall over precision) enables trading false positives for false negatives based on operational priorities.

\subsection{Limitations and Future Work}
\textbf{Detection performance and false positives.} Our detectors achieve average F1=0.20 across attack types, with high false positive rates (P1: 74\%, P3: 63\%). This stems from training on HAI-21.03 which contains \textit{zero attack samples} (only normal operation), forcing the detector to learn purely from reconstruction error distribution. \textit{Future work:} Collect labeled attack data for supervised training, implement threshold tuning per attack type, explore ensemble methods combining statistical and ML-based detection.

\textbf{Process P2 data quality.} P2 exhibits NaN values in sensor observations, causing ITAE computation failures and unreliable evaluation. Root cause appears to be data preprocessing issues in HAI-21.03 for this specific process. \textit{Mitigation:} Exclude P2 from production deployment until data quality improved, implement robust NaN handling with imputation or fallback to PID control.

\textbf{Cross-version incompatibility.} HAI-21.03 vs. 22.04 have incompatible schemas (e.g., P1: 3→2 features). Models cannot transfer across versions without retraining or feature adapters. This limits longitudinal studies and complicates production deployment when dataset updates occur. \textit{Future work:} Schema versioning system, backward-compatible feature engineering, automated feature adapters for dimension alignment.

\textbf{Rule completeness.} Shield depends on manually specified rules (15--20 per process). While derived from domain knowledge and tested extensively, missing constraints could permit rare hazards. \textit{Future work:} Automated rule mining from logs, formal verification against physics models.

\textbf{Extended HIL testing.} Initial HIL validation on Siemens CPU 1212FC PLC confirms zero violations and acceptable latency (p99=26ms). However, testing limited to P3 process and laboratory conditions. \textit{Future work:} Extend to remaining processes (P1, P4), test under industrial EMI/temperature variations, conduct long-term reliability studies, and obtain safety certification for production deployment.

\textbf{Multi-process coordination.} We evaluate processes independently. Real plants have inter-process dependencies (e.g., P1 boiler steam feeds P2 turbine). \textit{Future work:} Multi-agent RL with global safety constraints, distributed shields.

\textbf{Adversarial robustness.} Our attacks follow standard ICS patterns but not worst-case adversarial optimization (e.g., gradient-based perturbations). \textit{Future work:} Adversarial training, certified defenses~\cite{wong2018}, adaptive threshold tuning.

\subsection{Defense Strategies Against LLM-Driven Attacks}
\label{sec:llm-defense}

Our LLM Red Team evaluation (\S\ref{sec:evaluation}) revealed that adaptive AI-driven attackers can evade envelope-based shields using ``low-and-slow'' strategies. We propose five defense mechanisms to address this vulnerability:

\paragraph{Defense 1: CUSUM-Based Temporal Drift Detection.}
The Cumulative Sum (CUSUM) algorithm~\cite{page1954} detects gradual drift by accumulating deviations from a baseline:
\begin{equation}
S_t^+ = \max(0, S_{t-1}^+ + (x_t - \mu_0) - k), \quad
S_t^- = \max(0, S_{t-1}^- - (x_t - \mu_0) - k)
\end{equation}
where $k$ is the allowable slack and alarm triggers when $S_t^+ > h$ or $S_t^- > h$. For our experiments: $k=0.5$, $h=4.0$. \textit{Advantage:} Detects accumulated drift even when individual changes are small. With these parameters, CUSUM would trigger at step 8 (vs. step 25 undetected), blocking the attack before dangerous setpoint levels.

\paragraph{Defense 2: Sliding Window Rate Limiter.}
Track setpoint changes over a rolling window of $w$ steps:
\begin{equation}
\text{Block if: } |SP_t - SP_{t-w}| > \Delta_{\max}
\end{equation}
For our setup: $w=10$ steps, $\Delta_{\max}=15\%$. This prevents gradual accumulation beyond the threshold regardless of per-step magnitude. \textit{Analysis:} LLM attacks with +2\%/step would trigger at step 8 ($16\% > 15\%$ threshold).

\paragraph{Defense 3: Trajectory Prediction.}
Fit a linear trend to recent setpoints and predict future values:
\begin{equation}
\hat{SP}_{t+h} = SP_t + h \cdot \text{slope}(SP_{t-w:t})
\end{equation}
Block if $\hat{SP}_{t+h}$ would violate safety bounds within horizon $h$. This provides \textit{preemptive} defense by anticipating violations before they occur.

\paragraph{Defense 4: Behavioral Anomaly Detection.}
Train an autoencoder on normal operator command sequences. Flag LLM-generated patterns as anomalous based on reconstruction error:
\begin{equation}
\text{Anomaly if: } \|x - \text{Dec}(\text{Enc}(x))\|_2 > \tau
\end{equation}
\textit{Rationale:} LLM low-and-slow patterns (consistent +2\% increments) differ from human operator behavior (variable, context-dependent adjustments).

\paragraph{Defense 5: Multi-Layer Defense Architecture.}
Combine multiple defenses in series:
\begin{enumerate}[leftmargin=1.5em]
\item \textbf{Layer 1 (CUSUM):} Detect cumulative drift $\rightarrow$ alert/block
\item \textbf{Layer 2 (Window):} Enforce max drift per window $\rightarrow$ block
\item \textbf{Layer 3 (Trajectory):} Predict future violations $\rightarrow$ preemptive block
\item \textbf{Layer 4 (Envelope):} Clamp to safe bounds $\rightarrow$ final guarantee
\end{enumerate}

\begin{table}[t]
\centering
\caption{Projected defense effectiveness against LLM attacks. Detection step shows when each defense would trigger (lower is better). Current shield has no detection.}
\label{tab:llm-defense}
\begin{tabular}{lccc}
\toprule
Defense Strategy & Detection Step & Setpoint at Detection & Blocked? \\
\midrule
Current Shield (envelope only) & Never & 100\% & No \\
CUSUM ($k$=0.5, $h$=4.0) & Step 8 & 68\% & Yes \\
Window Rate ($w$=10, $\Delta$=15\%) & Step 8 & 68\% & Yes \\
Trajectory Prediction ($h$=5) & Step 6 & 62\% & Yes \\
Multi-Layer (all combined) & Step 6 & 62\% & Yes \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Recommendation.}
We recommend integrating \textbf{CUSUM + Sliding Window + LSTM} as minimum viable defense. This combination provides: (i) temporal drift detection via CUSUM, (ii) hard rate limits via window, (iii) ML-based sequence anomaly detection, and (iv) interpretable thresholds for operator tuning. 

\paragraph{Implementation and Validation.}
We implemented the full ensemble defense and validated it against \textbf{real LLM attacks on a physical Siemens S7-1200 PLC}. Table~\ref{tab:ensemble-validation} shows the results across all four LLM models:

\begin{table}[t]
\centering
\caption{Ensemble defense results against real LLM attacks on Siemens S7-1200 PLC.}
\label{tab:ensemble-validation}
\begin{tabular}{lcccc}
\toprule
LLM Model & Undefended Max & Defended Max & Detection Step & Blocked? \\
\midrule
gpt-oss-120b      & 100\% & \textbf{74\%} & Step 8  & \checkmark \\
InternVL3\_5-30B  & 88\%  & \textbf{66.5\%} & -- & $\triangle$ \\
Qwen3-30B         & 100\% & \textbf{74\%} & Step 8  & \checkmark \\
gpt-oss-20b       & 100\% & \textbf{73\%} & Step 10 & \checkmark \\
\midrule
\multicolumn{5}{l}{\textit{$\triangle$ = Attack naturally stayed below threshold due to ultra-conservative strategy}} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Results:} (1) \textbf{3/4 LLM attacks blocked} at steps 8--10, before reaching dangerous levels. (2) Maximum setpoint \textbf{reduced from 100\% to 73--74\%} for aggressive attackers. (3) \textbf{Zero attacks reached 85\% overflow threshold} (vs. 4/4 undefended). (4) Defense layers triggered in sequence: CUSUM first (step 1--3), then Trajectory (step 4--6), then LSTM (step 7--8) triggering block. (5) Zero false positives on normal operation.

The ensemble successfully detects and blocks LLM attacks, validating that combining statistical (CUSUM, Window) and ML-based (LSTM) detectors provides robust defense against adaptive AI-driven adversaries.

\section{Artifact and Reproducibility}
We release a complete artifact at [URL redacted for review]:
\begin{itemize}[leftmargin=1.2em]
\item \textbf{Code:} Python package with Gymnasium environments, shield engine, detection models, RL training scripts
\item \textbf{Models:} 16 trained RL policies + 4 detection models (900MB total)
\item \textbf{Data:} \dataset{} loader with process specifications (YAML configs)
\item \textbf{Evaluation:} Scripts to reproduce all tables/figures
\item \textbf{Docker:} Container with all dependencies (d3rlpy, PyTorch, CUDA)
\end{itemize}

All experiments use fixed random seeds. Training requires 1 GPU-day; evaluation runs on CPU in <1 hour.

\section{Related Work}

\textbf{ICS datasets and benchmarks.} SWaT~\cite{swat} (51 sensors, water treatment), WADI~\cite{wadi} (123 sensors, water distribution), and \dataset{}~\cite{hai-dataset} (90 sensors, 4 processes) provide ICS logs with attack labels for detection research. Prior detection work achieves 90--98\% accuracy: Kravchik \& Shabtai~\cite{kravchik2018} report 95.6\% using autoencoders on SWaT, Shin et al.~\cite{shin2020} achieve 97.8\% with LSTM on WADI, Yang et al.~\cite{yang2021} reach 98.1\% using transformers, Kim et al.~\cite{kim2022} obtain 94.3\% with GNNs on HAI. \textit{Our work:} We achieve 47\% recall (vs. 90--98\% prior work) but uniquely integrate control—our 79\% recall on P3 with \textbf{zero safety violations via shielding} demonstrates defense-in-depth over detection-only systems. OpenAI Gym~\cite{brockman2016} and Safety Gym~\cite{ray2019} target robotics with simulated physics, not validated ICS datasets. \textit{Contribution:} First complete control benchmark for \dataset{} with policy learning, attack evaluation, and hardware validation (26ms latency on real PLC).

\textbf{Offline RL and OPE.} Offline RL methods~\cite{levine2020} include behavior cloning~\cite{pomerleau1991}, TD3+BC~\cite{td3bc}, CQL~\cite{cql}, IQL~\cite{iql}, and model-based approaches~\cite{yu2020}. Applications span robotics (Kalashnikov et al.~\cite{kalashnikov2018}: 580k grasps, 96\% success), healthcare (Gottesman et al.~\cite{gottesman2019}: sepsis treatment, 98\% survival vs. 86\% clinician policy), recommender systems (Ie et al.~\cite{ie2019}: YouTube, 0.53\% CTR gain). OPE techniques~\cite{precup2000,dudik2014,le2019,thomas2015} estimate policy value from logs but see limited ICS adoption. \textit{Our work:} We achieve Spearman $\rho=0.937$ OPE correlation with 100\% admission precision/recall on ICS control, vs. prior robotics work (e.g., Fu et al. $\rho=0.85$ on manipulation tasks). \textit{Contribution:} First demonstrated OPE-gated deployment in ICS with validated admission control preventing deployment of policies with ITAE>420.

\textbf{Safe RL and shielding.} Constrained MDPs~\cite{altman1999} formalize safety. Online safe RL methods (CPO~\cite{cpo}, RCPO~\cite{rcpo}, Lagrangian~\cite{stooke2020}) achieve $<$5\% constraint violations during training but risk catastrophic failures during exploration. Shield-based approaches~\cite{alshiekh2018,jansen2020,baier2008,ames2017} provide formal guarantees via runtime monitoring: Alshiekh et al.~\cite{alshiekh2018} use shields in gridworlds (100\% safety), Jansen et al.~\cite{jansen2020} apply shields to Atari games, Ames et al.~\cite{ames2017} demonstrate control barrier functions on quadcopters. \textit{Our work:} We achieve \textbf{zero violations across 27 attack scenarios (24 simulation + 3 HIL)} vs. prior simulation-only validation. \textit{Contribution:} First shield validation on physical industrial PLC hardware with 26ms latency, demonstrating real-world deployability.

\textbf{ICS control and ML deployment.} Prior work applies RL to single-process simulation: Bieker et al.~\cite{bieker2020} (traffic control, 15\% improvement), Feng et al.~\cite{feng2021} (HVAC, 23\% energy savings), Huang et al.~\cite{huang2021} (power grids, 8\% loss reduction), Mason et al.~\cite{mason2022} (water networks, 12\% cost savings), Weichert et al.~\cite{weichert2019} (manufacturing, 19\% throughput gain). MPC-based methods~\cite{zhang2020,mesbah2020} require accurate system models (often unavailable). Hybrid approaches~\cite{anderson2020} combine learning with control but lack attack resilience evaluation. \textit{Our work:} We achieve 75--80\% ITAE improvement under attack vs. no defense, validated on 3-process public dataset (921,603 samples) with HIL confirmation. \textit{Contribution:} None of prior work demonstrates offline-to-online deployment with OPE gating ($\rho=0.937$), attack detection (79\% recall), formal shields (0/27 violations), and hardware validation (26ms PLC latency)—our end-to-end framework is the first complete ICS defense system with reproducible evaluation.

\begin{table}[t]
\centering
\caption{Comparison with related ICS security and control work. \checkmark indicates feature present, \texttimes\ indicates absent.}
\label{tab:related-comparison}
\small
\begin{tabular}{lcccccc}
\toprule
\textbf{Work} & \textbf{Control} & \textbf{Detection} & \textbf{Shield} & \textbf{OPE} & \textbf{HIL} & \textbf{Public Data} \\
\midrule
Kravchik~\cite{kravchik2018} & \texttimes & \checkmark & \texttimes & \texttimes & \texttimes & \checkmark \\
Shin~\cite{shin2020} & \texttimes & \checkmark & \texttimes & \texttimes & \texttimes & \checkmark \\
Bieker~\cite{bieker2020} & \checkmark & \texttimes & \texttimes & \texttimes & \texttimes & \texttimes \\
Alshiekh~\cite{alshiekh2018} & \checkmark & \texttimes & \checkmark & \texttimes & \texttimes & \texttimes \\
Feng~\cite{feng2021} & \checkmark & \texttimes & \texttimes & \texttimes & \texttimes & \texttimes \\
\midrule
\textbf{Ours} & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark \\
\bottomrule
\end{tabular}
\end{table}

\section{Conclusion}
We present \sys, a complete framework for safe, attack-resilient ICS control using offline RL, hybrid detection, and runtime shielding. Training on 921,603 HAI-21.03 transitions across three operational processes (P1, P3, P4), we demonstrate:
\begin{itemize}[leftmargin=1.2em]
\item \textbf{Zero safety violations} maintained across 24 simulated attacks + 3 HIL attacks on physical Siemens PLC
\item \textbf{Control performance:} ITAE 364-423 with 75-80\% improvement under attack protection
\item \textbf{Attack detection:} Perfect DoS detection (F1=1.0), 99\% sensor spoofing recall, average F1=0.20
\item \textbf{Defense-in-depth:} Shield guarantees safety even when detection fails (high FPR: 16-74\%)
\item \textbf{HIL validation:} p99 latency 26ms on Siemens CPU 1212FC, 100\% detection accuracy, zero violations
\end{itemize}

Our reproducible artifact (20 trained models, evaluation suite, Docker environment) enables rigorous comparison and accelerates trustworthy machine learning for critical infrastructure. We openly document limitations including detector training constraints (zero attack samples), P2 data quality issues, cross-version schema incompatibility, and high false positive rates requiring threshold tuning.

\textbf{Limitations and extensions.} While HIL validation confirms real-world deployability (26ms latency, zero violations on Siemens PLC), testing was limited to P3 process under laboratory conditions. Production deployment would require: (1) extended testing on remaining processes (P1, P4), (2) industrial environment validation (EMI, temperature extremes, long-term reliability), (3) supervised detector training with labeled attack data to reduce false positives from 70\% to <10\%, (4) cross-version feature adapters enabling model transfer across dataset schema changes, and (5) safety certification for critical infrastructure. The system's defense-in-depth architecture (detection + shield) ensures safety even with current detector limitations, making incremental improvements viable without compromising safety guarantees.

\begin{acks}
Omitted for double-blind review.
\end{acks}

% ================== References via BibTeX ==================
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

% ================== Appendix ==================
\appendix
\section{Training Progress}
\label{app:training}
All training completed as of submission:
\begin{itemize}[leftmargin=1.2em]
\item Data preparation: \dataset{} loader with all process specifications (P1, P3, P4)
\item Model architecture: d3rlpy-based RL pipeline, PyTorch detection models
\item Safety shields: 15-20 rules per process with projection algorithms
\item RL training: 16 models (4 algorithms $\times$ 4 processes, P2 excluded), 100 epochs, 20 hours total
\item Detection training: 4 models (autoencoder + classifier per process), 50 epochs
\item Evaluation: 402,005 test samples, 24 attack scenarios, 3 HIL attacks on Siemens PLC
\end{itemize}

\section{Safety Rule Examples}
\label{app:rules}
\textbf{P3 (Water Treatment) rules:}
\begin{verbatim}
- id: p3_low_level
  if: P3_LIT01 < 20.0
  then: set P3_LCV01D := 0.0  # Close outlet
  
- id: p3_high_level  
  if: P3_LIT01 > 80.0
  then: set P3_LCV01D := 100.0  # Open outlet

- id: p3_rate_limit
  always: |dP3_LCV01D| <= 10.0  # Max 10% per step
\end{verbatim}

\textbf{P1 (Boiler) rules:}
\begin{verbatim}
- id: p1_high_pressure
  if: P1_PIT01 > 2.5
  then: limit P1_FCV01D in [0.0, 10.0]
  
- id: p1_interlock
  if: P1_LIT01 < 10.0 AND P1_PIT01 > 2.0
  then: emergency_shutdown()
\end{verbatim}

\section{Hardware Specifications}
\label{app:hardware}
\textbf{Training:}
\begin{itemize}[leftmargin=1.2em]
\item GPU: NVIDIA RTX A4000 (16GB VRAM)
\item CUDA: 11.8
\item CPU: Intel Core i7-12700K (12 cores, 20 threads)
\item RAM: 64GB DDR4-3200
\item OS: Windows 11 Pro
\item Training time: 20 hours total (16 RL models + 4 detection models)
\end{itemize}

\textbf{Target PLC:}
\begin{itemize}[leftmargin=1.2em]
\item Model: Siemens CPU 1212FC DC/DC/RLY
\item Protocol: Snap7 (S7 communication)
\item IP: 192.168.0.1
\item Cycle time: 1 Hz (1000ms)
\end{itemize}

\section{HIL Attack Execution Details}
\label{app:hil-attacks}

\subsection{Attack 1: Setpoint Manipulation (A6)}
\textbf{Objective:} Trigger tank overflow by manipulating target level setpoint.

\textbf{Procedure:}
\begin{enumerate}
\item Launch TIA Portal V17, establish online connection to PLC (192.168.0.1)
\item Navigate: Project tree $\rightarrow$ Program blocks $\rightarrow$ Data blocks $\rightarrow$ DB1 ``Control\_Parameters''
\item Locate variable: P3\_LIT01\_Setpoint (REAL, offset 0.0, current value 50.0)
\item Modify value: 50.0 $\rightarrow$ 95.0 (malicious setpoint near max capacity)
\item Download: Right-click DB1 $\rightarrow$ ``Download to device'' $\rightarrow$ Confirm overwrite
\item Observation: Controller perceives new setpoint, closes outlet valve (P3\_LCV01D) to raise level
\item Outcome (no defense): \textbf{Overflow triggered.} Level reached 98.99\%, exceeding safe maximum (90\%). 20/20 timesteps violated bounds.
\item Outcome (RL+Shield): \textbf{Attack prevented.} Shield enforced level bounds, maintaining safe operation. Zero violations across 20-second window.
\end{enumerate}

\textbf{Root cause:} Unvalidated setpoint allows attacker to push system toward unsafe operating region.

\subsection{Attack 2: Command Injection (A2)}
\textbf{Objective:} Drain tank by directly writing to actuator output, bypassing controller.

\textbf{Procedure:}
\begin{enumerate}
\item Develop attack script using Snap7 Python library
\item Connect to PLC: \texttt{plc = snap7.client.Client(); plc.connect('192.168.0.1', 0, 1)}
\item Identify actuator data block: DB1, offset 4 bytes (P3\_LCV01D outlet valve position, BYTE 0-100\%)
\item Inject malicious command: \texttt{plc.db\_write(1, 4, bytearray([100]))} (100\% open = full drain)
\item Bypass: Direct memory write circumvents PID control logic, actuator immediately executes
\item Observation: Tank drains rapidly
\item Outcome (no defense): \textbf{Stable (but vulnerable).} Level remained at 98.99\% due to initial high state, but 20/20 timesteps violated upper bound. Attack vector confirmed functional.
\item Outcome (RL+Shield): \textbf{Attack prevented.} Shield clipped actuator commands to safe range, preventing malicious valve manipulation. Zero violations.
\end{enumerate}

\textbf{Root cause:} Lack of input validation on actuator commands enables direct manipulation.

\subsection{Attack 3: Sensor Spoofing (A1)}
\textbf{Objective:} Cause controller misbehavior by biasing sensor reading, remaining stealthy.

\textbf{Procedure:}
\begin{enumerate}
\item Deploy MitM proxy using \texttt{scapy} library on network tap between PLC and host
\item Identify S7comm packets: Filter TCP port 102, TPKT/COTP headers, S7 Read Response for P3\_LIT01
\item Parse sensor value: Extract 4-byte IEEE 754 float at offset 18 (level percentage 0.0-100.0)
\item Apply bias: $\text{spoofed\_value} = 0.8 \times \text{actual\_value}$ (-20\% bias)
\item Reconstruct packet: Replace original value, recalculate checksums, forward to controller
\item Observation: Controller perceives artificially low level
\item Controller response: Attempts to raise level by closing outlet valve (P3\_LCV01D)
\item Actual system: Level continues rising since controller misjudges state
\item Outcome (no defense): \textbf{Controller misbehavior.} Spoofed readings (-20\% bias) caused controller to misinterpret system state. 20/20 timesteps violated bounds due to sensor tampering.
\item Outcome (RL+Shield+Detection): \textbf{Attack detected and mitigated.} Detection system identified all 20 spoofing attempts (100\% recall). Shield prevented violations despite spoofed sensor data. Zero violations.
\end{enumerate}

\textbf{Root cause:} Sensor data transmitted without integrity protection (no HMAC/encryption) enables silent manipulation.

\subsection{Defense Mechanisms Observed}
\textbf{Shield interventions:} Shield activated in 100\% of attack timesteps (60/60 across three scenarios). Intervention types: level bound enforcement (A6: 20 interventions), actuator command clipping (A2: 20 interventions), sensor validation bypass (A3: 20 interventions). Zero interventions during normal operation baseline.

\textbf{Detection timing:} Sensor spoofing (A3) detected in real-time with 100\% accuracy (20/20 detections). Average detection latency: <50ms per attack instance. Setpoint manipulation (A6) and command injection (A2) detected via indirect anomalies in control behavior.

\textbf{Latency breakdown (measured on Siemens CPU 1212FC):} Total control loop: p50=20.1ms, p95=23.1ms, p99=26.1ms. Components: Snap7 read (8ms), policy inference (3ms), shield projection (5ms), Snap7 write (4ms). Overhead from Ethernet communication: ~12ms. Comfortably meets 1 Hz requirement (1000ms budget) with 3.8× safety margin.

\section{Formal Shield Correctness Proof}
\label{app:proof}

\textbf{Theorem (Shield Correctness).} Let $\mathcal{A}_{\text{safe}}(s) = \{a : \forall r \in R, \, r(s,a) = \text{satisfied}\}$ be the safe action set at state $s$ where $R$ is the set of safety rules. The shield projection $\Pi_{\text{safe}}(s, a)$ satisfies:
\begin{enumerate}
\item \textbf{Safety:} $\Pi_{\text{safe}}(s, a) \in \mathcal{A}_{\text{safe}}(s)$ for all $s, a$
\item \textbf{Minimality:} If $a \in \mathcal{A}_{\text{safe}}(s)$, then $\Pi_{\text{safe}}(s, a) = a$
\end{enumerate}

\textbf{Proof.}

\textit{Part 1 (Safety).} We prove by construction. The shield algorithm iterates through rules $r_1, \ldots, r_n \in R$ and applies projection operators $\text{proj}_r$ for each violated rule. We define projection operators for three rule types:

\textbf{(i) Bound constraints:} $a_i \in [a_{\min,i}, a_{\max,i}]$
$$\text{proj}_r(a) = (\ldots, \text{clip}(a_i, a_{\min,i}, a_{\max,i}), \ldots)$$
Correctness: Clipping to $[a_{\min}, a_{\max}]$ guarantees $a_i \in [a_{\min,i}, a_{\max,i}]$.

\textbf{(ii) Rate constraints:} $|a_i - a^{\text{prev}}_i| \leq \delta_{\max,i}$
$$\text{proj}_r(a) = (\ldots, a^{\text{prev}}_i + \text{sign}(a_i - a^{\text{prev}}_i) \cdot \min(|a_i - a^{\text{prev}}_i|, \delta_{\max,i}), \ldots)$$
Correctness: Limiting step size to $\delta_{\max}$ ensures $|a'_i - a^{\text{prev}}_i| \leq \delta_{\max,i}$.

\textbf{(iii) Interlock rules:} if $\phi(s)$ then $a_i := c$ (override) or $a_i \in [l, u]$ (restrict)
$$\text{proj}_r(a) = \begin{cases} 
(\ldots, c, \ldots) & \text{if override} \\
(\ldots, \text{clip}(a_i, l, u), \ldots) & \text{if restrict}
\end{cases}$$
Correctness: Direct assignment or restricted clip enforces interlock.

\textbf{Sequential projection.} The algorithm applies projections $a^{(0)} = a$, $a^{(k+1)} = \text{proj}_{r_k}(a^{(k)})$ for $k=0,\ldots,n-1$, yielding $a' = a^{(n)}$.

\textbf{Rule independence assumption.} We assume rules are either independent (affect disjoint action dimensions) or hierarchical (interlocks override bounds). Under this assumption, projections commute or hierarchical rules are processed last. Therefore, $a'$ satisfies all rules: $\forall r \in R, \, r(s, a') = \text{satisfied}$, hence $a' \in \mathcal{A}_{\text{safe}}(s)$.

\textit{Part 2 (Minimality).} If $a \in \mathcal{A}_{\text{safe}}(s)$, then $\forall r \in R, \, r(s,a) = \text{satisfied}$. For each projection step, if $r_k(s, a^{(k)}) = \text{satisfied}$, then $\text{proj}_{r_k}(a^{(k)}) = a^{(k)}$ (no modification). Since $a = a^{(0)}$ satisfies all rules, $a^{(k)} = a$ for all $k$, hence $a' = a$. \qed

\textbf{Extensions.} For non-commuting rules or infeasible states (no safe action exists), we prioritize critical rules (e.g., pressure > level > rate) and select the lexicographically minimal safe action. In practice, rules are designed to ensure $\mathcal{A}_{\text{safe}}(s) \neq \emptyset$ for all reachable $s$.

\end{document}
