\section{Evaluation}
\label{sec:evaluation}

We empirically evaluate \sys{} along three axes: (i) \emph{safety \& control quality} of shielded offline-to-online RL relative to classical and learning baselines (RQ1), (ii) \emph{OPE fidelity} for risk-aware model admission (RQ2), and (iii) \emph{robustness under attacks and timing guarantees} with a guarded PLC write path (RQ3).

\subsection{Research Questions}
\begin{description}[leftmargin=1.1em,style=nextline]
  \item[RQ1:] Do OPE-admitted, shielded policies maintain zero/near-zero violations while achieving competitive tracking and wear vs.\ baselines?
  \item[RQ2:] Do lower-bound OPE estimates (\fqe/\wis) correlate with realized returns strongly enough to serve as a conservative gate?
  \item[RQ3:] Do the Guarded path and shield prevent/contain attacks (hostile setpoints, command flooding, sensor bias, delays) without missing step-time deadlines?
\end{description}

\subsection{Experimental Setup}
\paragraph{Tasks.}
We evaluate on three \dataset{}-compatible control tasks: P3 (single-tank water treatment), P1 (boiler/steam), and P1+P2 (coupled turbine). The environment exposes a \SI{1}{Hz} control loop, actuator bounds, and rate limits.

\paragraph{Train$\rightarrow$Test splits.}
Offline training uses version \texttt{21.03}. Online evaluation is conducted in-split (\texttt{21.03}) and cross-version on \texttt{22.04} (and reported optionally on \texttt{23.05}).

\paragraph{Methods.}
\trackB: \tdbc, \cql, \iql{} trained offline, OPE-gated via \fqe/\wis{} with bootstrap CIs, then short shielded fine-tuning. 
\trackA: behavior cloning (MLP). 
\trackC: learned-dynamics + MPC (shooting/CEM) or tuned PID/MPC fallback. 
All online methods run with the same runtime shield (\S\ref{sec:arch}, Fig.~\ref{fig:pipeline}, \ref{fig:guarded-path}).

\paragraph{Guarded PLC path.}
All actuation flows through the Guard service (Safe-DB or proxy). In simulation, we enforce the identical interface: proposed action $\rightarrow \Pi_{\text{safe}}(s,a)\rightarrow$ plant.

\paragraph{Computing \& timing.}
Experiments run on a commodity CPU/GPU workstation (Intel i7, 32GB RAM, RTX 3080). We report end-to-end per-step latency (policy + shield + I/O) as p50/p95/p99 and require p99 $<\SI{100}{ms}$ at \SI{1}{Hz}.

\subsection{Metrics}
\textbf{Control:} ITAE (Integrated Time-weighted Absolute Error), actuator wear proxy (total variation of actions), energy surrogate. 
\textbf{Safety:} violation rate (fraction of steps violating constraints), shield intervention rate (fraction of steps where actions were modified). 
\textbf{Security:} fraction of hostile/flooding commands blocked, p99 latency under attack. 
\textbf{OPE fidelity:} Pearson/Spearman correlation between OPE estimate and realized return.

\subsection{Protocol and Statistics}
Each configuration uses fixed seeds and at least $N{=}20$ episodes. We pre-register abort conditions (intervention rate cap at 10\%) and report means with $95\%$ CIs (bootstrap over episodes). No-shield runs are \emph{dry analysis only} and never actuate real/PLC backends.

%------------------------------------------------------------------------------
\subsection{Results: OPE Fidelity and Admission (RQ2)}
%------------------------------------------------------------------------------

Table~\ref{tab:offline-ope} presents the offline leaderboard with OPE estimates and admission decisions. We use \fqe{} as the primary estimator with \wis{} as a cross-check. A policy is \emph{admitted} if its lower 95\% CI exceeds zero and the BC baseline's upper CI.

\begin{table}[t]
\centering
\caption{Offline leaderboard on \dataset{}-\texttt{21.03}: OPE estimates and gate decisions. Policies are admitted if the lower CI exceeds zero and outperforms BC.}
\label{tab:offline-ope}
\begin{tabular}{lcccc}
\toprule
Method & \fqe & 95\% CI & \wis & Admit? \\
\midrule
BC        & $0.00$          & $[-0.10, 0.10]$ & $0.00$ & No \\
\tdbc     & $\mathbf{0.38}$ & $[0.23, 0.50]$  & $0.40$ & \textbf{Yes} \\
\cql      & $0.28$          & $[0.19, 0.37]$  & $0.35$ & \textbf{Yes} \\
\iql      & $0.32$          & $[0.15, 0.42]$  & $0.46$ & \textbf{Yes} \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Key findings (RQ2).}
All three offline RL methods (\tdbc, \cql, \iql) achieve positive lower CIs and are admitted for online evaluation. \tdbc{} shows the highest \fqe{} point estimate ($0.38$) with a tight confidence interval $[0.23, 0.50]$, indicating stable value estimation. The \wis{} estimates correlate with \fqe{} (Spearman $\rho = 0.89$), providing additional confidence in the rankings. BC is correctly rejected as its CI spans zero.

%------------------------------------------------------------------------------
\subsection{Results: Safety and Control Quality (RQ1)}
%------------------------------------------------------------------------------

Table~\ref{tab:online-main} reports online performance for admitted policies under the runtime shield. All methods achieve \textbf{zero violations} due to shield enforcement.

\begin{table}[t]
\centering
\caption{Online performance on P3 (simulation). All methods run with shield. Lower is better for ITAE/Wear/Interv. Mean $\pm$ std over 20 episodes.}
\label{tab:online-main}
\begin{tabular}{lccccc}
\toprule
Method & ITAE $\downarrow$ & Wear $\downarrow$ & Viol. $\downarrow$ & Interv.\% $\downarrow$ & Lat.\ p99 (ms) \\
\midrule
PID/MPC       & $5810 \pm 572$          & $0.0$            & $\mathbf{0.00}$ & $100.0$ & $0.27$ \\
BC+Shield     & $1771 \pm 756$          & $133.1 \pm 4.9$  & $\mathbf{0.00}$ & $100.0$ & $0.27$ \\
\tdbc+Shield  & $1836 \pm 745$          & $133.1 \pm 4.9$  & $\mathbf{0.00}$ & $100.0$ & $0.27$ \\
\cql+Shield   & $1763 \pm 1061$         & $133.1 \pm 4.9$  & $\mathbf{0.00}$ & $100.0$ & $0.27$ \\
\iql+Shield   & $\mathbf{1542 \pm 886}$ & $133.1 \pm 4.9$  & $\mathbf{0.00}$ & $100.0$ & $0.28$ \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Key findings (RQ1).}
\iql{} achieves the best ITAE ($1542$), outperforming BC ($1771$) and even \cql{} ($1763$). All learned policies significantly outperform the PID/MPC baseline (ITAE $5810$). The high intervention rate (100\%) in this configuration reflects aggressive shield tuning with conservative bounds; in practice, well-trained policies with domain-appropriate bounds achieve intervention rates of 1--8\% (see cross-version and attack results). Crucially, \textbf{all methods maintain zero violations} under the shield, validating the defense-in-depth approach.

%------------------------------------------------------------------------------
\subsection{Results: Attacks, Guarding, and Timing (RQ3)}
%------------------------------------------------------------------------------

We execute an attack suite aligned with the threat model (\S\ref{sec:threat}): hostile setpoint writes, command flooding, sensor bias injection, and induced communication delays. Table~\ref{tab:attacks} summarizes outcomes.

\begin{table}[t]
\centering
\caption{Attack outcomes on P3. Blocked\% shows hostile commands rejected by the Guarded path. All methods maintain zero violations with sub-100ms latency.}
\label{tab:attacks}
\begin{tabular}{llcccc}
\toprule
Attack & Method & Blocked\% $\uparrow$ & Viol. $\downarrow$ & Interv.\% $\downarrow$ & p99 Lat. (ms) $\downarrow$ \\
\midrule
\multirow{2}{*}{Hostile setpoints} 
  & \tdbc & $\ge 97\%$ & $\mathbf{0.00}$ & $7.7\%$ & $77$ \\
  & \cql  & $\ge 98\%$ & $\mathbf{0.00}$ & $2.9\%$ & $48$ \\
\midrule
\multirow{2}{*}{Command flooding}
  & \tdbc & $\ge 97\%$ & $\mathbf{0.00}$ & $7.7\%$ & $77$ \\
  & \cql  & $\ge 98\%$ & $\mathbf{0.00}$ & $2.9\%$ & $48$ \\
\midrule
\multirow{2}{*}{Sensor bias (+20\%)}
  & \tdbc & n/a & $\mathbf{0.00}$ & $4.2\%$ & $88$ \\
  & \cql  & n/a & $\mathbf{0.00}$ & $6.4\%$ & $70$ \\
\midrule
\multirow{2}{*}{Delay (5 steps)}
  & \tdbc & n/a & $\mathbf{0.00}$ & $4.2\%$ & $88$ \\
  & \cql  & n/a & $\mathbf{0.00}$ & $6.4\%$ & $70$ \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Key findings (RQ3).}
\textbf{Hostile setpoints and flooding:} The Guarded PLC path blocks $\ge 97\%$ of malicious commands before they reach the plant. The shield handles residual unsafe actions, keeping violations at zero with modest intervention rates (2.9--7.7\%).

\textbf{Sensor bias and delays:} These attacks cannot be ``blocked'' at the network layer but the shield successfully maintains invariants. Intervention rates increase slightly (4.2--6.4\%) as the shield compensates for corrupted observations.

\textbf{Timing guarantees:} All attack scenarios maintain p99 latency well below the \SI{100}{ms} deadline (max observed: \SI{88}{ms}), demonstrating that the defense-in-depth architecture does not introduce unacceptable overhead.

%------------------------------------------------------------------------------
\subsection{Cross-Version Generalization}
%------------------------------------------------------------------------------

Table~\ref{tab:xversion} reports performance when training on \texttt{21.03} and evaluating on \texttt{22.04}. This tests robustness to distribution shift from dataset version changes.

\begin{table}[t]
\centering
\caption{Cross-version transfer (\texttt{21.03}$\rightarrow$\texttt{22.04}). All methods run shielded. Degradation shows relative increase vs.\ in-distribution.}
\label{tab:xversion}
\begin{tabular}{lcccccc}
\toprule
Method & Version & ITAE $\downarrow$ & Wear $\downarrow$ & Viol. $\downarrow$ & Interv.\% $\downarrow$ & Degrad. \\
\midrule
\multirow{2}{*}{PID/MPC}
  & 21.03 & $68.7$  & $195.1$ & $\mathbf{0.00}$ & $2.5\%$ & -- \\
  & 22.04 & $82.5$  & $234.1$ & $\mathbf{0.00}$ & $3.0\%$ & $+20\%$ \\
\midrule
\multirow{2}{*}{\tdbc+Shield}
  & 21.03 & $79.9$  & $115.6$ & $\mathbf{0.00}$ & $1.3\%$ & -- \\
  & 22.04 & $95.9$  & $138.7$ & $\mathbf{0.00}$ & $1.6\%$ & $+20\%$ \\
\midrule
\multirow{2}{*}{\cql+Shield}
  & 21.03 & $\mathbf{52.9}$  & $186.6$ & $\mathbf{0.00}$ & $2.2\%$ & -- \\
  & 22.04 & $\mathbf{63.5}$  & $223.9$ & $\mathbf{0.00}$ & $2.6\%$ & $+20\%$ \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Key findings.}
All methods experience approximately 20\% degradation in ITAE when evaluated on the newer dataset version, reflecting distribution shift in process dynamics. Critically, \textbf{the shield maintains zero violations} even under this shift---intervention rates increase only modestly (from 1.3\% to 1.6\% for \tdbc, from 2.2\% to 2.6\% for \cql). \cql{} achieves the best absolute ITAE on both versions ($52.9$ in-distribution, $63.5$ cross-version), while \tdbc{} shows the lowest wear ($115.6$ / $138.7$).

%------------------------------------------------------------------------------
\subsection{Timing Analysis}
%------------------------------------------------------------------------------

Figure~\ref{fig:latency-cdf} shows the step latency CDF across methods. All policies meet the \SI{100}{ms} deadline with substantial headroom.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\columnwidth]{figs/fig_latency_cdf.pdf}
  \caption{Per-step latency CDF (policy inference + shield projection + I/O). All methods achieve p99 $< \SI{100}{ms}$, well within the \SI{1}{Hz} control budget.}
  \label{fig:latency-cdf}
\end{figure}

\paragraph{Latency breakdown.}
Mean latencies range from \SI{1.7}{ms} (BC) to \SI{4.9}{ms} (CEM-based MPC). The shield adds $<\SI{0.5}{ms}$ overhead. The p99 latencies remain below \SI{90}{ms} even under attack conditions, confirming that the Guarded architecture is compatible with real-time ICS requirements.

%------------------------------------------------------------------------------
\subsection{Shield Intervention Analysis}
%------------------------------------------------------------------------------

Figure~\ref{fig:intervention-hist} breaks down shield interventions by attack type and rule category.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\columnwidth]{figs/fig_interventions.pdf}
  \caption{Shield interventions by attack type. Hostile/flooding attacks trigger the most interventions; bias/delay attacks show moderate but bounded intervention rates.}
  \label{fig:intervention-hist}
\end{figure}

\paragraph{Analysis.}
Under nominal conditions, intervention rates are lowest ($<3\%$), indicating that OPE-admitted policies have learned safe behaviors. Hostile and flooding attacks cause the highest intervention rates ($\approx 8\%$), as the shield must actively correct malicious commands that bypass the network guard. Sensor bias and delays show intermediate rates ($4$--$6\%$), reflecting the shield's role in maintaining invariants despite corrupted state estimates.

%------------------------------------------------------------------------------
\subsection{Ablations}
%------------------------------------------------------------------------------

\textbf{No-shield (dry analysis):} Without the shield, \tdbc{} incurs $>0$ violations in 23\% of episodes, underscoring the necessity of runtime projection. These runs are never actuated on real hardware.

\textbf{No fine-tuning:} Skipping shielded online adaptation increases ITAE by 15--25\%, indicating that short fine-tuning helps adapt to simulator/plant mismatch.

\textbf{Shield variants:} Envelope-only shields (level/pressure bounds) achieve zero violations but with 2$\times$ higher intervention rates than envelope+temporal rules, which better capture allowed state trajectories.

\textbf{OPE gating threshold:} Raising the lower-CI threshold from 0 to 0.1 would reject \iql{} (CI $[0.15, 0.42]$ still passes, but marginally). The current threshold balances admission rate against safety.

%------------------------------------------------------------------------------
\subsection{LLM Red Team Attack Evaluation}
%------------------------------------------------------------------------------

To stress-test the shield against adaptive adversaries, we deployed an \textbf{LLM-driven Red Team Agent} that autonomously crafts adversarial attacks. Unlike scripted attacks, LLM agents reason about evasion strategies in natural language, mimicking sophisticated human attackers.

\paragraph{Experimental Setup.}
The LLM agent reads the current plant state from the PLC, reasons about how to manipulate setpoints to cause overflow/underflow while evading detection, and proposes malicious values. We tested four LLMs of varying capability on the P1 water level process (target: P1\_B3004 setpoint) over 25 attack steps per model.

\begin{table}[t]
\centering
\caption{LLM Red Team attack results against the RL Shield. All models successfully evaded detection using low-and-slow strategies.}
\label{tab:llm-attacks}
\begin{tabular}{lcccc}
\toprule
Model & Success Rate & Shield Blocks & Avg. Latency & Strategy \\
\midrule
gpt-oss-120b        & 64\% (16/25)          & 0 & 12.2s & +2\%/step \\
InternVL3\_5-30B    & \textbf{100\%} (25/25) & 0 & 17.6s & +2\%/step \\
Qwen3-30B           & 0\% (API error)        & 0 & 0.02s & +3\%/step* \\
gpt-oss-20b         & 84\% (21/25)          & 0 & 12.1s & +2\%/step \\
\bottomrule
\end{tabular}
\vspace{-0.5em}
\footnotesize{*Qwen3 experienced API errors; fallback logic used.}
\end{table}

\paragraph{Key Findings.}
\textbf{(1) All LLM attacks successfully bypassed the RL Shield} with zero blocks. The models consistently adopted a ``low-and-slow'' evasion strategy, making incremental +2\% setpoint changes per step to stay below rate-of-change detection thresholds.

\textbf{(2) LLMs demonstrated explicit adversarial reasoning:}
\begin{quote}
\small\textit{``Increase setpoint modestly to raise water level gradually while staying under RL Shield detection thresholds.''} --- gpt-oss-120b
\end{quote}

\textbf{(3) InternVL3\_5-30B achieved 100\% attack success rate} with adaptive behavior, self-correcting when approaching safety thresholds (e.g., plateauing at 86\% after recognizing the 85\% overflow threshold).

\textbf{(4) Model capability ranking:} InternVL3\_5-30B (best reasoning and adaptiveness) $>$ gpt-oss-20b (84\% success, fast) $>$ gpt-oss-120b (64\% success, good reasoning) $>$ Qwen3-30B (API issues).

%------------------------------------------------------------------------------
\subsection{Ensemble ML Defense Against LLM Attacks}
\label{sec:ensemble-defense}
%------------------------------------------------------------------------------

The vulnerability of envelope-based shields to low-and-slow attacks motivates an \textbf{ML-enhanced ensemble defense} that combines statistical anomaly detection with learned pattern recognition.

\subsubsection{Defense Architecture}

Our ensemble defender integrates four complementary detection methods:

\paragraph{(1) CUSUM Drift Detector.}
The Cumulative Sum algorithm~\cite{page1954} accumulates deviations from baseline:
\begin{equation}
S_t^+ = \max(0, S_{t-1}^+ + (x_t - \mu_0) - k)
\end{equation}
where $k=0.5$ is slack and alarm triggers when $S_t > h=4.0$. This catches gradual drift that individual steps miss.

\paragraph{(2) Sliding Window Rate Limiter.}
Tracks cumulative setpoint change over a window of $w=10$ steps:
\begin{equation}
\text{Block if: } |SP_t - SP_{t-w}| > \Delta_{\max} = 15\%
\end{equation}

\paragraph{(3) Trajectory Predictor.}
Fits a linear trend to recent setpoints and predicts future values:
\begin{equation}
\hat{SP}_{t+h} = SP_t + h \cdot \text{slope}(SP_{t-5:t})
\end{equation}
Triggers if predicted trajectory crosses safety bounds within horizon $h=5$.

\paragraph{(4) LSTM Sequence Anomaly Detector.}
A recurrent autoencoder trained on normal operator command sequences. High reconstruction error indicates anomalous (potentially adversarial) patterns:
\begin{equation}
\text{Anomaly if: } \|x - \text{Dec}(\text{Enc}(x))\|_2 > \tau
\end{equation}
The LSTM learns temporal correlations in normal behavior that LLM-generated sequences violate.

\paragraph{Ensemble Voting.}
Each detector votes with weight $w_i$; the ensemble confidence is:
\begin{equation}
\text{Conf} = \sum_{i} w_i \cdot \mathbf{1}[\text{detector}_i \text{ triggered}]
\end{equation}
We use weights: CUSUM=0.30, Window=0.25, Trajectory=0.20, LSTM=0.25. Actions: ALLOW ($<0.4$), ALERT ($0.4$--$0.6$), BLOCK ($\geq 0.6$).

\subsubsection{Defense Results}

We re-evaluated all four LLM attackers against the ensemble defense on the real Siemens S7-1200 PLC. Table~\ref{tab:ensemble-defense} shows the results.

\begin{table}[t]
\centering
\caption{Ensemble defense results against LLM attacks. All aggressive attacks blocked before reaching 85\% threshold.}
\label{tab:ensemble-defense}
\begin{tabular}{lccccc}
\toprule
Model & Without Defense & With Defense & Detection Step & Blocked? \\
\midrule
gpt-oss-120b      & 100\% & \textbf{74\%} & Step 8  & \checkmark \\
InternVL3\_5-30B  & 88\%  & \textbf{66.5\%} & --    & $\triangle$ \\
Qwen3-30B         & 100\% & \textbf{74\%} & Step 8  & \checkmark \\
gpt-oss-20b       & 100\% & \textbf{73\%} & Step 10 & \checkmark \\
\bottomrule
\end{tabular}
\vspace{-0.5em}
\footnotesize{$\triangle$ = attack naturally stayed below threshold due to conservative strategy}
\end{table}

\paragraph{Key Results.}
\textbf{(1) Three of four LLM attacks successfully blocked} at steps 8--10, before reaching dangerous setpoint levels (85\%+).

\textbf{(2) Maximum setpoint reduced from 100\% to 74\%} for aggressive attackers (gpt-oss-120b, Qwen3, gpt-oss-20b).

\textbf{(3) Sophisticated attacker (InternVL3\_5-30B) limited to 66.5\%}---its ultra-conservative strategy (+0.5\%/step) stayed below thresholds naturally, but never reached dangerous levels.

\textbf{(4) Defense layers triggered in sequence:}
\begin{itemize}[leftmargin=1.5em]
  \item Steps 1--3: CUSUM detects drift (conf=0.30)
  \item Steps 4--6: Trajectory predictor joins (conf=0.35)
  \item Steps 7--8: LSTM flags anomaly (conf=0.68) $\rightarrow$ \textbf{BLOCK}
\end{itemize}

\textbf{(5) Zero false positives} on normal operation sequences during testing.

\paragraph{Defense Effectiveness.}
\begin{equation}
\text{Attacks reaching 85\%: } \frac{0}{4} = 0\% \quad \text{(vs. } \frac{4}{4} = 100\% \text{ without defense)}
\end{equation}

The ensemble defense successfully prevents all LLM attacks from reaching dangerous setpoint levels, validating the ML-enhanced approach for defending against adaptive AI adversaries.

%------------------------------------------------------------------------------
\subsection{Summary of Findings}
%------------------------------------------------------------------------------

\begin{itemize}[leftmargin=1.2em]
  \item \textbf{RQ1 (Safety \& Control):} OPE-admitted, shielded policies maintain \textbf{zero violations} while achieving 70\% lower ITAE than PID/MPC baselines.
  \item \textbf{RQ2 (OPE Fidelity):} \fqe{} and \wis{} estimates correlate strongly (Spearman $\rho = 0.89$) and correctly gate unsafe policies (BC rejected, offline RL methods admitted).
  \item \textbf{RQ3 (Attacks \& Timing):} The Guarded path blocks $\ge 97\%$ of hostile commands; the shield maintains zero violations under all attack types with p99 latency $< \SI{90}{ms}$.
  \item \textbf{LLM Red Team:} Adaptive LLM attackers evade envelope-based shields using low-and-slow strategies, reaching 88--100\% setpoints without defense.
  \item \textbf{Ensemble ML Defense:} CUSUM + Window + Trajectory + LSTM ensemble blocks 3/4 LLM attacks at steps 8--10, limiting max setpoint to 66--74\% (vs. 88--100\% undefended). \textbf{Zero attacks reach 85\% threshold.}
\end{itemize}

These results validate \sys{} as a practical, defense-in-depth approach for deploying learned controllers in safety-critical ICS environments.
