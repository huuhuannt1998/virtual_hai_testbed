# ==============================================================================
# P1 (Boiler) Baseline Evaluation Configuration
# ==============================================================================
# This configuration file defines all hyperparameters for running the complete
# evaluation pipeline on the P1 boiler subprocess.

experiment:
  name: "p1_boiler_baseline"
  description: "Baseline evaluation for P1 boiler control with safety shields"
  seed: 42
  device: "cuda"  # or "cpu"
  
# Schema defining process dynamics and safety constraints
schema:
  path: "../schemas/p1.yaml"

# Dataset configuration
data:
  csv_path: "data/hai/train_p1.csv"
  val_csv_path: "data/hai/val_p1.csv"
  test_csv_path: "data/hai/test_p1.csv"
  output_dir: "data/processed/p1"
  
  # Preprocessing
  normalize: true
  reward_scale: 1.0
  terminal_threshold: 0.1
  
  # Train/val/test split (if using single file)
  train_frac: 0.7
  val_frac: 0.15
  test_frac: 0.15

# Gymnasium environment wrapper
environment:
  max_steps: 3600       # 1 hour at 1 Hz
  action_repeat: 1
  frame_stack: 1
  reward_shaping: true
  
  # Attack injection (for robustness testing)
  attack:
    enabled: false
    type: null           # hostile, flood, bias, delay
    params: {}

# Behavior Cloning (Track A baseline)
bc:
  enabled: true
  
  # Architecture
  hidden_dims: [256, 256, 256]
  activation: "relu"
  dropout: 0.1
  
  # Training
  batch_size: 256
  learning_rate: 3.0e-4
  weight_decay: 1.0e-4
  n_epochs: 100
  early_stopping_patience: 10
  
  # Regularization
  grad_clip_norm: 1.0
  
  # Output
  model_path: "models/p1/bc/policy.pt"
  log_dir: "logs/p1/bc"

# Offline RL (Track B)
offline_rl:
  enabled: true
  
  # Algorithms to train
  algorithms:
    - name: "td3bc"
      enabled: true
      params:
        alpha: 2.5           # BC regularization weight
        actor_lr: 3.0e-4
        critic_lr: 3.0e-4
        tau: 0.005
        gamma: 0.99
        n_critics: 2
        hidden_dims: [256, 256]
        
    - name: "cql"
      enabled: true
      params:
        alpha: 5.0           # CQL regularization weight
        actor_lr: 3.0e-4
        critic_lr: 3.0e-4
        tau: 0.005
        gamma: 0.99
        n_critics: 2
        hidden_dims: [256, 256]
        
    - name: "iql"
      enabled: true
      params:
        expectile: 0.7       # Expectile for value function
        actor_lr: 3.0e-4
        critic_lr: 3.0e-4
        tau: 0.005
        gamma: 0.99
        hidden_dims: [256, 256]
  
  # Common training settings
  training:
    batch_size: 256
    n_steps: 100000
    eval_interval: 10000
    n_eval_episodes: 10
    grad_clip_norm: 1.0
    
  # Output
  model_dir: "models/p1/offline_rl"
  log_dir: "logs/p1/offline_rl"

# Off-Policy Evaluation
ope:
  enabled: true
  
  # FQE settings
  fqe:
    n_steps: 50000
    learning_rate: 3.0e-4
    batch_size: 256
    hidden_dims: [256, 256]
    gamma: 0.99
    
  # Weighted Importance Sampling
  wis:
    n_trajectories: 100
    
  # Bootstrap for confidence intervals
  bootstrap:
    n_bootstrap: 200
    confidence_level: 0.95
    
  # Admission gating
  gate:
    require_positive_lower_ci: true
    require_beat_bc: true
    
  output_csv: "results/p1_offline_leaderboard.csv"

# Safety Shield
shield:
  enabled: true
  
  # Rule parsing from schema
  use_schema_rules: true
  
  # Action projection
  projection_method: "clip"  # clip or project
  max_delta_per_step: 0.1
  
  # Logging
  log_interventions: true
  intervention_penalty: -0.01

# Model Predictive Control (Track C)
mpc:
  enabled: true
  
  # Dynamics model
  dynamics:
    type: "mlp"
    hidden_dims: [256, 256]
    residual: true
    
    training:
      n_epochs: 50
      batch_size: 256
      learning_rate: 1.0e-3
      weight_decay: 1.0e-4
      val_frac: 0.1
      
    model_path: "models/p1/mpc/dynamics.pt"
    
  # CEM planner
  cem:
    horizon: 10
    n_candidates: 500
    n_elite: 50
    n_iterations: 5
    init_std: 0.3
    min_std: 0.01

# Online Evaluation
online_eval:
  enabled: true
  
  # Episode settings
  n_episodes: 50
  max_steps_per_episode: 3600
  
  # Shielded evaluation
  use_shield: true
  max_intervention_rate: 0.05  # Abort if exceeded
  
  # Metrics to compute
  metrics:
    - "itae"
    - "ise"
    - "overshoot"
    - "settling_time"
    - "wear"
    - "energy"
    - "violations"
    - "interventions"
    - "latency"
    
  output_csv: "results/p1_nominal.csv"

# Attack Evaluation
attack_eval:
  enabled: true
  
  attacks:
    - type: "hostile"
      params:
        adversary_magnitude: 0.5
        
    - type: "flood"
      params:
        flood_prob: 0.1
        
    - type: "bias"
      params:
        bias_magnitude: 0.2
        
    - type: "delay"
      params:
        delay_steps: 3
        
  n_episodes_per_attack: 20
  output_csv: "results/p1_attacks.csv"

# Cross-version Evaluation
cross_version:
  enabled: false
  versions:
    - "p1_v1"
    - "p1_v2"
  output_csv: "results/p1_cross_version.csv"

# Plotting
plots:
  enabled: true
  output_dir: "paper/figs"
  format: "pdf"  # pdf or png
  dpi: 300
  
  figures:
    - type: "ope_scatter"
      output: "fig_p1_ope_scatter.pdf"
      
    - type: "latency_cdf"
      output: "fig_p1_latency_cdf.pdf"
      deadline_ms: 10.0
      
    - type: "interventions"
      output: "fig_p1_interventions.pdf"

# Logging and Outputs
logging:
  level: "INFO"
  log_to_file: true
  log_dir: "logs/p1"
  tensorboard: true
  wandb:
    enabled: false
    project: "hai-ml"
    entity: null
    
results:
  base_dir: "results/p1"
  save_trajectories: false
  save_models: true
